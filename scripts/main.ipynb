{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10152313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Ra√≠z del Proyecto: c:\\Users\\Edward\\Desktop\\Bancomext\\Estatales\n",
      "üìÇ Datos Crudos: c:\\Users\\Edward\\Desktop\\Bancomext\\Estatales\\data\\raw\n",
      "üìÇ Datos Procesados: c:\\Users\\Edward\\Desktop\\Bancomext\\Estatales\\data\\intermediate\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üöÄ INICIANDO ETL ESTATAL UNIFICADO üöÄ\n",
      "\n",
      "‚è≥ [PIB] Iniciando extracci√≥n exhaustiva...\n",
      "‚è≥ [Exportaciones] Iniciando extracci√≥n detallada...\n",
      "‚è≥ [Poblaci√≥n] Iniciando extracci√≥n de pir√°mide completa...\n",
      "‚è≥ [ENOE] Iniciando descarga y procesamiento...\n",
      "‚è≥ [Educaci√≥n] Procesando anuario (Generando Top 3 separados)...\n",
      "‚è≥ [IED] Procesando datos complejos (Totales 3 D√≠gitos y Detalle)...\n",
      "‚è≥ [SAIC] Procesando censo...\n",
      "‚è≥ [IMCO] Procesando competitividad...\n",
      "‚úÖ [IMCO] Completado.\n",
      "‚úÖ [SAIC] Completado.\n",
      "‚úÖ [Educaci√≥n] Completado (Totales + 2 Archivos Top3 - Ciclo 2024-2025).\n",
      "   üì• Descargando: https://www.inegi.org.mx/contenidos/programas/enoe/15ymas/tabulados/enoe_indicadores_estrategicos_2025_trim3_xls.zip\n",
      "‚úÖ [IED] Completado (Periodo (2025, 3)).\n",
      "‚úÖ [ENOE] Completado (2025-trim3).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import io\n",
    "import re\n",
    "import concurrent.futures\n",
    "from datetime import datetime\n",
    "\n",
    "def homologar_estado(nombre):\n",
    "    if not isinstance(nombre, str): return nombre\n",
    "    n = nombre.lower()\n",
    "    \n",
    "    if 'ciudad de m√©xico' in n or 'ciudad de mexico' in n or 'cdmx' in n or 'distrito federal' in n: return 'Ciudad de M√©xico'\n",
    "    if 'baja california sur' in n: return 'Baja California Sur'\n",
    "    if 'baja california' in n: return 'Baja California'\n",
    "    if 'estado de m√©xico' in n or 'estado de mexico' in n or n.strip() == 'm√©xico' or n.strip() == 'mexico': return 'M√©xico'\n",
    "    \n",
    "    if 'coahuila' in n: return 'Coahuila'\n",
    "    if 'michoac√°n' in n or 'michoacan' in n: return 'Michoac√°n'\n",
    "    if 'veracruz' in n: return 'Veracruz'\n",
    "    if 'nuevo le√≥n' in n or 'nuevo leon' in n: return 'Nuevo Le√≥n'\n",
    "    if 'quer√©taro' in n or 'queretaro' in n: return 'Quer√©taro'\n",
    "    if 'san luis' in n: return 'San Luis Potos√≠'\n",
    "    if 'yucat√°n' in n or 'yucatan' in n: return 'Yucat√°n'\n",
    "    \n",
    "    estados = ['Aguascalientes', 'Campeche', 'Colima', 'Chiapas', 'Chihuahua', \n",
    "               'Durango', 'Guanajuato', 'Guerrero', 'Hidalgo', 'Jalisco', \n",
    "               'Morelos', 'Nayarit', 'Oaxaca', 'Puebla', 'Quintana Roo', \n",
    "               'Sinaloa', 'Sonora', 'Tabasco', 'Tamaulipas', 'Tlaxcala', 'Zacatecas']\n",
    "    \n",
    "    for est in estados:\n",
    "        if est.lower() in n: return est\n",
    "        \n",
    "    return nombre\n",
    "\n",
    "def limpiar_columna_estado(df):\n",
    "    nombres_validos = ['estado', 'entidad', 'entidad federativa', 'estados', 'entidades']\n",
    "    for col in df.columns:\n",
    "        if str(col).lower().strip() in nombres_validos:\n",
    "            df[col] = df[col].apply(homologar_estado)\n",
    "    return df\n",
    "\n",
    "# ==========================================\n",
    "# 0. CONFIGURACI√ìN GLOBAL Y RUTAS\n",
    "# ==========================================\n",
    "TOKEN_INEGI = \"129ac2e3-e8a6-72c7-58c1-acced5a601bd\"\n",
    "\n",
    "# Detecci√≥n robusta de directorios\n",
    "try:\n",
    "    SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "    if os.path.basename(SCRIPT_DIR) == 'scripts':\n",
    "        PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)\n",
    "    else:\n",
    "        PROJECT_ROOT = SCRIPT_DIR\n",
    "except NameError:\n",
    "    PROJECT_ROOT = os.getcwd()\n",
    "    if os.path.basename(PROJECT_ROOT) == 'scripts':\n",
    "        PROJECT_ROOT = os.path.dirname(PROJECT_ROOT)\n",
    "\n",
    "RAW_DIR = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "INTERMEDIATE_DIR = os.path.join(PROJECT_ROOT, \"data\", \"intermediate\")\n",
    "\n",
    "os.makedirs(INTERMEDIATE_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"üìç Ra√≠z del Proyecto: {PROJECT_ROOT}\")\n",
    "print(f\"üìÇ Datos Crudos: {RAW_DIR}\")\n",
    "print(f\"üìÇ Datos Procesados: {INTERMEDIATE_DIR}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ==========================================\n",
    "# M√ìDULO 1: PIB (API)\n",
    "# ==========================================\n",
    "def procesar_pib():\n",
    "    print(\"‚è≥ [PIB] Iniciando extracci√≥n exhaustiva...\")\n",
    "    indicadores = {\n",
    "        \"746097\": \"Total Nacional\",\n",
    "        \"746196\": \"Actividades Primarias\",\n",
    "        \"746229\": \"Agricultura, cr√≠a y explotaci√≥n de animales, aprovechamiento forestal, pesca y caza\",\n",
    "        \"746262\": \"Agricultura\",\n",
    "        \"746295\": \"Cr√≠a y explotaci√≥n de animales\",\n",
    "        \"746328\": \"Pesca, caza y captura\",\n",
    "        \"746361\": \"Aprovechamiento forestal\",\n",
    "        \"746394\": \"Actividades Secundarias\",\n",
    "        \"746427\": \"Miner√≠a\",\n",
    "        \"746460\": \"Miner√≠a petrolera\",\n",
    "        \"746493\": \"Miner√≠a no petrolera\",\n",
    "        \"746526\": \"Generaci√≥n, transmisi√≥n y distribuci√≥n de energ√≠a el√©ctrica, agua y gas\",\n",
    "        \"746559\": \"Construcci√≥n\",\n",
    "        \"746592\": \"Industrias manufactureras\",\n",
    "        \"746625\": \"Industria alimentaria\",\n",
    "        \"746658\": \"Bebidas y tabaco\",\n",
    "        \"746691\": \"Insumos, acabados y productos textiles\",\n",
    "        \"746724\": \"Prendas de vestir y productos de cuero y piel\",\n",
    "        \"746757\": \"Industria de la madera\",\n",
    "        \"746790\": \"Industria del papel\",\n",
    "        \"746823\": \"Productos derivados del petr√≥leo y carb√≥n, qu√≠mica, pl√°stico y hule\",\n",
    "        \"746856\": \"Productos a base de minerales no met√°licos\",\n",
    "        \"746889\": \"Met√°licas b√°sicas y productos met√°licos\",\n",
    "        \"746922\": \"Maquinaria y equipo, computaci√≥n, electr√≥nicos y accesorios\",\n",
    "        \"746955\": \"Muebles, colchones y persianas\",\n",
    "        \"746988\": \"Otras industrias manufactureras\",\n",
    "        \"747021\": \"Actividades Terciarias\",\n",
    "        \"747054\": \"Comercio al por mayor\",\n",
    "        \"747087\": \"Comercio al por menor\",\n",
    "        \"747120\": \"Transportes, correos y almacenamiento\",\n",
    "        \"747153\": \"Informaci√≥n en medios masivos\",\n",
    "        \"747186\": \"Servicios financieros y de seguros\",\n",
    "        \"747219\": \"Servicios inmobiliarios y de alquiler de bienes\",\n",
    "        \"747252\": \"Servicios profesionales, cient√≠ficos y t√©cnicos\",\n",
    "        \"747285\": \"Corporativos\",\n",
    "        \"747318\": \"Servicios de apoyo a los negocios y manejo de residuos\",\n",
    "        \"747351\": \"Servicios educativos\",\n",
    "        \"747384\": \"Servicios de salud y de asistencia social\",\n",
    "        \"747417\": \"Servicios de esparcimiento culturales y deportivos\",\n",
    "        \"747450\": \"Servicios de alojamiento temporal y de preparaci√≥n de alimentos y bebidas\",\n",
    "        \"747483\": \"Otros servicios excepto actividades gubernamentales\",\n",
    "        \"747516\": \"Actividades legislativas, gubernamentales\"\n",
    "    }\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for ind_clave, ind_nombre in indicadores.items():\n",
    "        for i in range(0, 33): \n",
    "            clave_estado = f\"{i:02d}\"\n",
    "            url = f\"https://www.inegi.org.mx/app/api/indicadores/desarrolladores/jsonxml/INDICATOR/{ind_clave}/es/{clave_estado}/false/BIE-BISE/2.0/{TOKEN_INEGI}?type=json\"\n",
    "            \n",
    "            exito = False\n",
    "            for intento in range(3):\n",
    "                try:\n",
    "                    r = requests.get(url, timeout=10)\n",
    "                    if r.status_code == 200:\n",
    "                        data = r.json()\n",
    "                        if 'Series' in data and data['Series']:\n",
    "                            serie = data['Series'][0].get('OBSERVATIONS', [])\n",
    "                            serie_sorted = sorted(serie, key=lambda x: x.get('TIME_PERIOD', ''))\n",
    "                            if len(serie_sorted) >= 2:\n",
    "                                obs_list = serie_sorted[-2:]\n",
    "                            else:\n",
    "                                obs_list = serie_sorted\n",
    "                                \n",
    "                            for obs in obs_list:\n",
    "                                resultados.append({\n",
    "                                    'Indicador': ind_nombre,\n",
    "                                    'Clave_Indicador': ind_clave,\n",
    "                                    'Estado_ID': obs.get('COBER_GEO', clave_estado),\n",
    "                                    'Periodo': int(obs.get('TIME_PERIOD')),\n",
    "                                    'Valor': float(obs.get('OBS_VALUE', 0))\n",
    "                                })\n",
    "                        exito = True\n",
    "                        break\n",
    "                    else:\n",
    "                        time.sleep(1)\n",
    "                except Exception:\n",
    "                    time.sleep(1)\n",
    "            time.sleep(0.05)\n",
    "            \n",
    "    if resultados:\n",
    "        df = pd.DataFrame(resultados)\n",
    "        outfile = os.path.join(INTERMEDIATE_DIR, \"pib_entidad.csv\")\n",
    "        df.to_csv(outfile, index=False)\n",
    "        return f\"‚úÖ [PIB] Completado ({len(df)} registros).\"\n",
    "    return \"‚ö†Ô∏è [PIB] No se obtuvieron datos.\"\n",
    "\n",
    "# ==========================================\n",
    "# M√ìDULO 2: EXPORTACIONES (API)\n",
    "# ==========================================\n",
    "def procesar_exportaciones():\n",
    "    print(\"‚è≥ [Exportaciones] Iniciando extracci√≥n detallada...\")\n",
    "    indicadores = {\n",
    "        \"629659\": \"Total\",\n",
    "        \"696790\": \"Agricultura\",\n",
    "        \"696791\": \"Cr√≠a y explotaci√≥n de animales\",\n",
    "        \"697788\": \"Pesca, caza y captura\",\n",
    "        \"629660\": \"Extracci√≥n de petr√≥leo y gas\",\n",
    "        \"629661\": \"Miner√≠a de minerales met√°licos y no met√°licos\",\n",
    "        \"629662\": \"Industria alimentaria\",\n",
    "        \"629663\": \"Industria de las bebidas y del tabaco\",\n",
    "        \"629664\": \"Fabricaci√≥n de insumos textiles y acabado de textiles\",\n",
    "        \"629665\": \"Fabricaci√≥n de productos textiles, excepto prendas de vestir\",\n",
    "        \"629666\": \"Fabricaci√≥n de prendas de vestir\",\n",
    "        \"629667\": \"Curtido y acabado de cuero y piel, y fabricaci√≥n de productos de cuero\",\n",
    "        \"629668\": \"Industria de la madera\",\n",
    "        \"629669\": \"Industria del papel\",\n",
    "        \"629670\": \"Impresi√≥n e industrias conexas\",\n",
    "        \"629671\": \"Fabricaci√≥n de productos derivados del petr√≥leo y del carb√≥n\",\n",
    "        \"629672\": \"Industria qu√≠mica\",\n",
    "        \"629673\": \"Industria del pl√°stico y del hule\",\n",
    "        \"629674\": \"Fabricaci√≥n de productos a base de minerales no met√°licos\",\n",
    "        \"629675\": \"Industrias met√°licas b√°sicas\",\n",
    "        \"629676\": \"Fabricaci√≥n de productos met√°licos\",\n",
    "        \"629677\": \"Fabricaci√≥n de maquinaria y equipo\",\n",
    "        \"629678\": \"Fabricaci√≥n de equipo de computaci√≥n, comunicaci√≥n, medici√≥n y otros equipos, componentes y accesorios electr√≥nicos\",\n",
    "        \"629679\": \"Fabricaci√≥n de accesorios, aparatos el√©ctricos y equipo de generaci√≥n de energ√≠a el√©ctrica\",\n",
    "        \"629680\": \"Fabricaci√≥n de equipo de transporte\",\n",
    "        \"629681\": \"Fabricaci√≥n de muebles, colchones y persianas\",\n",
    "        \"629682\": \"Otras industrias manufactureras\",\n",
    "        \"629683\": \"No especificado\"\n",
    "    }\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for ind_clave, ind_nombre in indicadores.items():\n",
    "        for i in range(1, 33):\n",
    "            clave_estado = f\"{i:02d}\"\n",
    "            url = f\"https://www.inegi.org.mx/app/api/indicadores/desarrolladores/jsonxml/INDICATOR/{ind_clave}/es/{clave_estado}/false/BIE-BISE/2.0/{TOKEN_INEGI}?type=json\"\n",
    "            \n",
    "            exito = False\n",
    "            for intento in range(3):\n",
    "                try:\n",
    "                    r = requests.get(url, timeout=10)\n",
    "                    if r.status_code == 200:\n",
    "                        data = r.json()\n",
    "                        if 'Series' in data and data['Series']:\n",
    "                            serie = data['Series'][0].get('OBSERVATIONS', [])\n",
    "                            serie_sorted = sorted(serie, key=lambda x: x.get('TIME_PERIOD', ''))\n",
    "                            if serie_sorted:\n",
    "                                max_year_str = serie_sorted[-1]['TIME_PERIOD'][:4]\n",
    "                                try:\n",
    "                                    max_year = int(max_year_str)\n",
    "                                    min_year_target = max_year - 1\n",
    "                                    for obs in serie_sorted:\n",
    "                                        anio_obs = int(obs['TIME_PERIOD'][:4])\n",
    "                                        if anio_obs >= min_year_target:\n",
    "                                            resultados.append({\n",
    "                                                'Sector': ind_nombre,\n",
    "                                                'Clave_Indicador': ind_clave,\n",
    "                                                'Estado_ID': clave_estado,\n",
    "                                                'Periodo': obs.get('TIME_PERIOD'),\n",
    "                                                'Valor': float(obs.get('OBS_VALUE', 0))\n",
    "                                            })\n",
    "                                except: pass\n",
    "                        exito = True\n",
    "                        break\n",
    "                    else:\n",
    "                        time.sleep(1)\n",
    "                except Exception:\n",
    "                    time.sleep(1)\n",
    "            time.sleep(0.05)\n",
    "            \n",
    "    if resultados:\n",
    "        df = pd.DataFrame(resultados)\n",
    "        outfile = os.path.join(INTERMEDIATE_DIR, \"exportaciones_entidad.csv\")\n",
    "        df.to_csv(outfile, index=False)\n",
    "        return f\"‚úÖ [Exportaciones] Completado ({len(df)} registros).\"\n",
    "    return \"‚ö†Ô∏è [Exportaciones] No se obtuvieron datos.\"\n",
    "\n",
    "# ==========================================\n",
    "# M√ìDULO 3: POBLACI√ìN (API)\n",
    "# ==========================================\n",
    "def procesar_poblacion_api():\n",
    "    print(\"‚è≥ [Poblaci√≥n] Iniciando extracci√≥n de pir√°mide completa...\")\n",
    "    indicadores = {\n",
    "        # Hombres\n",
    "        \"1002000059\": \"0 a 4 a√±os (Hombres)\",\n",
    "        \"1002000089\": \"5 a 9 a√±os (Hombres)\",\n",
    "        \"1002000062\": \"10 a 14 a√±os (Hombres)\",\n",
    "        \"1002000068\": \"15 a 19 a√±os (Hombres)\",\n",
    "        \"1002000071\": \"20 a 24 a√±os (Hombres)\",\n",
    "        \"1002000074\": \"25 a 29 a√±os (Hombres)\",\n",
    "        \"1002000077\": \"30 a 34 a√±os (Hombres)\",\n",
    "        \"1002000080\": \"35 a 39 a√±os (Hombres)\",\n",
    "        \"1002000083\": \"40 a 44 a√±os (Hombres)\",\n",
    "        \"1002000086\": \"45 a 49 a√±os (Hombres)\",\n",
    "        \"1002000092\": \"50 a 54 a√±os (Hombres)\",\n",
    "        \"1002000095\": \"55 a 59 a√±os (Hombres)\",\n",
    "        \"1002000098\": \"60 a 64 a√±os (Hombres)\",\n",
    "        \"1002000101\": \"65 a 69 a√±os (Hombres)\",\n",
    "        \"1002000104\": \"70 a 74 a√±os (Hombres)\",\n",
    "        \"1002000107\": \"75 a 79 a√±os (Hombres)\",\n",
    "        \"1002000110\": \"80 a 84 a√±os (Hombres)\",\n",
    "        \"1002000113\": \"85 a 89 a√±os (Hombres)\",\n",
    "        \"1002000116\": \"90 a 94 a√±os (Hombres)\",\n",
    "        \"1002000119\": \"95 a 99 a√±os (Hombres)\",\n",
    "        \"1002000065\": \"100 a√±os y m√°s (Hombres)\",\n",
    "\n",
    "        # Mujeres\n",
    "        \"1002000060\": \"0 a 4 a√±os (Mujeres)\",\n",
    "        \"1002000090\": \"5 a 9 a√±os (Mujeres)\",\n",
    "        \"1002000063\": \"10 a 14 a√±os (Mujeres)\",\n",
    "        \"1002000069\": \"15 a 19 a√±os (Mujeres)\",\n",
    "        \"1002000072\": \"20 a 24 a√±os (Mujeres)\",\n",
    "        \"1002000075\": \"25 a 29 a√±os (Mujeres)\",\n",
    "        \"1002000078\": \"30 a 34 a√±os (Mujeres)\",\n",
    "        \"1002000081\": \"35 a 39 a√±os (Mujeres)\",\n",
    "        \"1002000084\": \"40 a 44 a√±os (Mujeres)\",\n",
    "        \"1002000087\": \"45 a 49 a√±os (Mujeres)\",\n",
    "        \"1002000093\": \"50 a 54 a√±os (Mujeres)\",\n",
    "        \"1002000096\": \"55 a 59 a√±os (Mujeres)\",\n",
    "        \"1002000099\": \"60 a 64 a√±os (Mujeres)\",\n",
    "        \"1002000102\": \"65 a 69 a√±os (Mujeres)\",\n",
    "        \"1002000105\": \"70 a 74 a√±os (Mujeres)\",\n",
    "        \"1002000108\": \"75 a 79 a√±os (Mujeres)\",\n",
    "        \"1002000111\": \"80 a 84 a√±os (Mujeres)\",\n",
    "        \"1002000114\": \"85 a 89 a√±os (Mujeres)\",\n",
    "        \"1002000117\": \"90 a 94 a√±os (Mujeres)\",\n",
    "        \"1002000120\": \"95 a 99 a√±os (Mujeres)\",\n",
    "        \"1002000066\": \"100 a√±os y m√°s (Mujeres)\"\n",
    "}\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for ind_clave, desc in indicadores.items():\n",
    "        for i in range(0, 33):\n",
    "            url = f\"https://www.inegi.org.mx/app/api/indicadores/desarrolladores/jsonxml/INDICATOR/{ind_clave}/es/{i:02d}/true/BISE/2.0/{TOKEN_INEGI}?type=json\"\n",
    "            \n",
    "            exito = False\n",
    "            for intento in range(3):\n",
    "                try:\n",
    "                    r = requests.get(url, timeout=5)\n",
    "                    if r.status_code == 200:\n",
    "                        data = r.json()\n",
    "                        if 'Series' in data and data['Series']:\n",
    "                            obs = data['Series'][0]['OBSERVATIONS'][0]\n",
    "                            resultados.append({\n",
    "                                'Indicador': desc,\n",
    "                                'Clave_Indicador': ind_clave,\n",
    "                                'Estado_ID': f\"{i:02d}\",\n",
    "                                'Periodo': obs.get('TIME_PERIOD'),\n",
    "                                'Valor': float(obs.get('OBS_VALUE', 0))\n",
    "                            })\n",
    "                        exito = True\n",
    "                        break\n",
    "                    else:\n",
    "                        time.sleep(0.5)\n",
    "                except Exception:\n",
    "                    time.sleep(0.5)\n",
    "            time.sleep(0.02)\n",
    "            \n",
    "    if resultados:\n",
    "        df = pd.DataFrame(resultados)\n",
    "        outfile = os.path.join(INTERMEDIATE_DIR, \"poblacion_edad.csv\")\n",
    "        df.to_csv(outfile, index=False)\n",
    "        return f\"‚úÖ [Poblaci√≥n] Completado ({len(df)} registros).\"\n",
    "    return \"‚ö†Ô∏è [Poblaci√≥n] No se obtuvieron datos.\"\n",
    "\n",
    "# ==========================================\n",
    "# M√ìDULO 4: ENOE (Descarga + PEA Corregida)\n",
    "# ==========================================\n",
    "def procesar_enoe_auto():\n",
    "    print(\"‚è≥ [ENOE] Iniciando descarga y procesamiento...\")\n",
    "    \n",
    "    base_url = \"https://www.inegi.org.mx/contenidos/programas/enoe/15ymas/tabulados/\"\n",
    "    anio_actual = datetime.now().year\n",
    "    url_final, anio_found, trim_found = None, None, None\n",
    "    \n",
    "    encontrado = False\n",
    "    for a in [anio_actual, anio_actual-1]:\n",
    "        if encontrado: break\n",
    "        for t in [\"trim4\", \"trim3\", \"trim2\", \"trim1\"]:\n",
    "            test_url = f\"{base_url}enoe_indicadores_estrategicos_{a}_{t}_xls.zip\"\n",
    "            try:\n",
    "                r = requests.head(test_url, timeout=5)\n",
    "                content_type = r.headers.get('Content-Type', '').lower()\n",
    "                if r.status_code == 200 and ('zip' in content_type or 'octet-stream' in content_type):\n",
    "                    url_final = test_url; anio_found = a; trim_found = t; encontrado = True\n",
    "                    break\n",
    "            except: pass\n",
    "            \n",
    "    if not url_final: return \"‚ùå [ENOE] URL no encontrada.\"\n",
    "\n",
    "    try:\n",
    "        print(f\"   üì• Descargando: {url_final}\")\n",
    "        r = requests.get(url_final)\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        \n",
    "        archivos = [f for f in z.namelist() if (\"Entidades/\" in f or \"Nacional/\" in f) and (f.endswith('.xlsx') or f.endswith('.xls'))]\n",
    "        \n",
    "        datos = []\n",
    "        \n",
    "        config_enoe = {\n",
    "            \"Poblacion Total\": [\"\", \"Poblaci√≥n total\"],\n",
    "            \"PEA\": [\"\", \"Poblaci√≥n econ√≥micamente activa (PEA)\"],\n",
    "            \"Desocupada\": [\"Poblaci√≥n econ√≥micamente activa\", \"Desocupada\"],\n",
    "            \"Edad Promedio PEA\": [\"Edad de la poblaci√≥n econ√≥micamente activa\", \"Promedio\"],\n",
    "            \"Sector Primario\": [\"3.2 Sector de actividad\", \"Primario\"],\n",
    "            \"Sector Secundario\": [\"3.2 Sector de actividad\", \"Secundario\"],\n",
    "            \"Sector Terciario\": [\"3.2 Sector de actividad\", \"Terciario\"],\n",
    "            \"No especificado\": [\"3.2 Sector de actividad\", \"No especificado\"],\n",
    "            \"Educacion Sup\": [\"Nivel de instrucci√≥n\", \"Medio superior y superior\"],\n",
    "            \"Informalidad TIL1\": [\"\", \"Tasa de informalidad laboral 1 (TIL1)\"]\n",
    "        }\n",
    "\n",
    "        for arch in archivos:\n",
    "            if \"Nacional\" in arch:\n",
    "                estado = \"Nacional\"\n",
    "            else:\n",
    "                estado = arch.split(\"Entidad_\")[-1].replace(\".xlsx\", \"\").replace(\".xls\", \"\").replace(\"_\", \" \").title()\n",
    "                \n",
    "            with z.open(arch) as f:\n",
    "                df = pd.read_excel(f, header=None)\n",
    "            \n",
    "            registro = {'Estado': estado, 'Anio': anio_found, 'Trimestre': trim_found}\n",
    "            \n",
    "            col_val = 4 \n",
    "            for idx, row in df.iterrows():\n",
    "                txt = \" \".join([str(x).lower() for x in row[:5]])\n",
    "                if \"poblaci√≥n total\" in txt:\n",
    "                    for c in range(4, min(15, len(row))):\n",
    "                        try:\n",
    "                            if float(str(row[c]).replace(\",\",\"\").replace(\" \", \"\")) > 1000: \n",
    "                                col_val = c; break\n",
    "                        except: continue\n",
    "                    break\n",
    "            \n",
    "            context = {i:\"\" for i in range(5)}\n",
    "            sticky = {1:\"\"}\n",
    "            \n",
    "            for idx, row in df.iterrows():\n",
    "                cols = [str(row[i]).strip() if i < len(row) and pd.notna(row[i]) else \"\" for i in range(5)]\n",
    "                indent = -1\n",
    "                txt_row = \"\"\n",
    "                \n",
    "                for i, txt in enumerate(cols):\n",
    "                    if txt:\n",
    "                        indent = i; txt_row = txt; context[i] = txt\n",
    "                        for j in range(i+1, 5): \n",
    "                            context[j] = \"\"; \n",
    "                            if j in sticky: sticky[j]=\"\"\n",
    "                        break\n",
    "                \n",
    "                if not txt_row: continue\n",
    "                \n",
    "                if indent == 1 and re.match(r'^(\\d+\\.?\\d*)\\s', txt_row): sticky[1] = txt_row\n",
    "                \n",
    "                path = [context[0]]\n",
    "                if indent == 1 and not re.match(r'^(\\d+\\.?\\d*)\\s', txt_row) and sticky[1]:\n",
    "                    path.append(sticky[1]); path.append(txt_row)\n",
    "                else: path.append(context[1])\n",
    "                path += [context[k] for k in range(2,5)]\n",
    "                \n",
    "                path_str = \" | \".join([p.lower() for p in path if p])\n",
    "                \n",
    "                for kpi, (padre, target) in config_enoe.items():\n",
    "                    if target.lower() in txt_row.lower() and padre.lower() in path_str:\n",
    "                        try: \n",
    "                            val_str = str(row[col_val]).replace(\",\",\"\").replace(\" \", \"\")\n",
    "                            registro[kpi] = float(val_str)\n",
    "                        except: pass\n",
    "            \n",
    "            datos.append(registro)\n",
    "\n",
    "        df_out = pd.DataFrame(datos)\n",
    "        df_out = limpiar_columna_estado(df_out)\n",
    "        outfile = os.path.join(INTERMEDIATE_DIR, \"enoe_indicadores.csv\")\n",
    "        df_out.to_csv(outfile, index=False)\n",
    "        return f\"‚úÖ [ENOE] Completado ({anio_found}-{trim_found}).\"\n",
    "        \n",
    "    except Exception as e: return f\"‚ùå [ENOE] Error: {e}\"\n",
    "\n",
    "# ==========================================\n",
    "# M√ìDULO 5: EDUCACI√ìN (Local)\n",
    "# ==========================================\n",
    "def procesar_educacion():\n",
    "    print(\"‚è≥ [Educaci√≥n] Procesando anuario (Generando Top 3 separados)...\")\n",
    "    \n",
    "    archivos = [f for f in os.listdir(RAW_DIR) if f.startswith(\"base_anuario_\") and f.endswith(\".xlsx\")]\n",
    "    if not archivos:\n",
    "        return \"‚ö†Ô∏è [Educaci√≥n] Falta archivo base_anuario_####-####.xlsx\"\n",
    "    \n",
    "    archivo_anuario = archivos[0]\n",
    "    fpath = os.path.join(RAW_DIR, archivo_anuario)\n",
    "    \n",
    "    match = re.search(r'base_anuario_(\\d{4}-\\d{4})\\.xlsx', archivo_anuario)\n",
    "    ciclo_val = match.group(1) if match else \"¬ø?\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(fpath, sheet_name=\"Base de datos\")\n",
    "        \n",
    "        # Limpieza de columnas num√©ricas\n",
    "        cols_num = ['Matr√≠cula Total', 'Egresados Total']\n",
    "        for c in cols_num: \n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)\n",
    "        \n",
    "        mapa_niveles = {\n",
    "            'T√âCNICO SUPERIOR': 'T√©cnico Superior', 'LICENCIATURA EN EDUCACI√ìN NORMAL': 'Licenciatura',\n",
    "            'LICENCIATURA UNIVERSITARIA Y TECNOL√ìGICA': 'Licenciatura', 'ESPECIALIDAD': 'Licenciatura',\n",
    "            'MAESTR√çA': 'Maestr√≠a', 'DOCTORADO': 'Doctorado'\n",
    "        }\n",
    "        df['Nivel_Agrupado'] = df['NIVEL'].str.upper().str.strip().map(mapa_niveles)\n",
    "        df = limpiar_columna_estado(df)\n",
    "        \n",
    "        # --- 1. TOTALES (INTACTO) ---\n",
    "        df_totales = df.groupby(['ENTIDAD', 'Nivel_Agrupado'])[cols_num].sum().reset_index()\n",
    "        df_totales['Ciclo'] = ciclo_val\n",
    "        df_totales.to_csv(os.path.join(INTERMEDIATE_DIR, \"educacion_totales.csv\"), index=False)\n",
    "        \n",
    "        df_campos = df.groupby(['ENTIDAD', 'Nivel_Agrupado', 'CAMPO AMPLIO'])[cols_num].sum().reset_index()\n",
    "        \n",
    "        df_nivels = df_campos.groupby(['ENTIDAD', 'Nivel_Agrupado'])[cols_num].sum().reset_index().rename(columns={\n",
    "            'Matr√≠cula Total': 'Total_Mat', \n",
    "            'Egresados Total': 'Total_Egr'\n",
    "        })\n",
    "        df_campos = df_campos.merge(df_nivels, on=['ENTIDAD', 'Nivel_Agrupado'])\n",
    "        \n",
    "        df_campos['Participacion_Matricula'] = df_campos.apply(lambda x: (x['Matr√≠cula Total']/x['Total_Mat']*100) if x['Total_Mat']>0 else 0, axis=1)\n",
    "        df_campos['Participacion_Egresados'] = df_campos.apply(lambda x: (x['Egresados Total']/x['Total_Egr']*100) if x['Total_Egr']>0 else 0, axis=1)\n",
    "        \n",
    "        top_mat = df_campos.sort_values(['ENTIDAD', 'Nivel_Agrupado', 'Matr√≠cula Total'], ascending=[True, True, False])\n",
    "        top_mat = top_mat.groupby(['ENTIDAD', 'Nivel_Agrupado']).head(3).copy()\n",
    "        top_mat['Ciclo'] = ciclo_val\n",
    "        \n",
    "        cols_mat = ['ENTIDAD', 'Nivel_Agrupado', 'CAMPO AMPLIO', 'Matr√≠cula Total', 'Participacion_Matricula', 'Ciclo']\n",
    "        top_mat[cols_mat].to_csv(os.path.join(INTERMEDIATE_DIR, \"educacion_top3_matricula.csv\"), index=False)\n",
    "        \n",
    "        top_egr = df_campos.sort_values(['ENTIDAD', 'Nivel_Agrupado', 'Egresados Total'], ascending=[True, True, False])\n",
    "        top_egr = top_egr.groupby(['ENTIDAD', 'Nivel_Agrupado']).head(3).copy()\n",
    "        top_egr['Ciclo'] = ciclo_val\n",
    "        \n",
    "        cols_egr = ['ENTIDAD', 'Nivel_Agrupado', 'CAMPO AMPLIO', 'Egresados Total', 'Participacion_Egresados', 'Ciclo']\n",
    "        top_egr[cols_egr].to_csv(os.path.join(INTERMEDIATE_DIR, \"educacion_top3_egresados.csv\"), index=False)\n",
    "        \n",
    "        return f\"‚úÖ [Educaci√≥n] Completado (Totales + 2 Archivos Top3 - Ciclo {ciclo_val}).\"\n",
    "        \n",
    "    except Exception as e: return f\"‚ùå [Educaci√≥n] Error: {e}\"\n",
    "# ==========================================\n",
    "# M√ìDULO 6: IED (Local) - GRUPOS POR SECTOR Y SIN %\n",
    "# ==========================================\n",
    "def procesar_ied():\n",
    "    print(\"‚è≥ [IED] Procesando datos complejos (Totales 3 D√≠gitos y Detalle)...\")\n",
    "    fpath = os.path.join(RAW_DIR, \"2025_3T_Flujosporentidadfederativa_orig__11_A1.xlsx\")\n",
    "    \n",
    "    if not os.path.exists(fpath): \n",
    "        return f\"‚ö†Ô∏è [IED] Falta {fpath}\"\n",
    "    \n",
    "    try:\n",
    "        # 1. MAPEO DE COLUMNAS\n",
    "        df_head = pd.read_excel(fpath, sheet_name='Actividad econ√≥mica_SCIAN 2023', header=None, nrows=10)\n",
    "        \n",
    "        header_idx = None\n",
    "        for idx, row in df_head.iterrows():\n",
    "            if \"Entidad Federativa\" in str(row[0]):\n",
    "                header_idx = idx\n",
    "                break\n",
    "        \n",
    "        if header_idx is None: return \"‚ùå [IED] Sin encabezados.\"\n",
    "        \n",
    "        years_row = df_head.iloc[header_idx].tolist()\n",
    "        quarters_row = df_head.iloc[header_idx + 1].tolist()\n",
    "        \n",
    "        col_map = {}\n",
    "        current_year = None\n",
    "        for i in range(1, len(years_row)):\n",
    "            if pd.notna(years_row[i]):\n",
    "                try:\n",
    "                    y = int(float(years_row[i]))\n",
    "                    if y > 2000: current_year = y\n",
    "                except: pass\n",
    "            if current_year and pd.notna(quarters_row[i]):\n",
    "                try:\n",
    "                    q = int(float(quarters_row[i]))\n",
    "                    if 1 <= q <= 4: col_map[i] = (current_year, q)\n",
    "                except: pass\n",
    "        \n",
    "        if not col_map: return \"‚ùå [IED] Error mapeo columnas.\"\n",
    "        \n",
    "        last_period = max(col_map.values()) # (A√±o, Trim)\n",
    "        prev_period = (last_period[0]-1, last_period[1])\n",
    "        \n",
    "        idx_act = [k for k, v in col_map.items() if v == last_period][0]\n",
    "        idx_prev = [k for k, v in col_map.items() if v == prev_period]\n",
    "        idx_prev = idx_prev[0] if idx_prev else None\n",
    "        \n",
    "        # 2. EXTRACCI√ìN (Solo 3 d√≠gitos)\n",
    "        df_data = pd.read_excel(fpath, sheet_name='Actividad econ√≥mica_SCIAN 2023', header=header_idx+2)\n",
    "        \n",
    "        def clean(x):\n",
    "            if pd.isna(x): return 0.0\n",
    "            s = str(x).strip().replace(',','')\n",
    "            try: return float(s)\n",
    "            except: return 0.0\n",
    "            \n",
    "        def clasificar(cod):\n",
    "            if cod.startswith('1'): return 'Primaria'\n",
    "            if cod.startswith(('2','3')): return 'Secundaria'\n",
    "            return 'Terciaria'\n",
    "            \n",
    "        filas = []\n",
    "        estado_act = None\n",
    "        \n",
    "        for i, row in df_data.iterrows():\n",
    "            c = str(row.iloc[0]).strip()\n",
    "            if not c or c == 'nan': continue\n",
    "            \n",
    "            match = re.match(r'^(\\d{2,6}|31-33)\\s+(.*)', c)\n",
    "            if match:\n",
    "                cod, desc = match.groups()\n",
    "                # Filtro Estricto: Solo 3 d√≠gitos\n",
    "                if len(cod) == 3 and cod != '31-33':\n",
    "                    val_act = clean(row.iloc[idx_act])\n",
    "                    val_prev = clean(row.iloc[idx_prev]) if idx_prev else 0.0\n",
    "                    \n",
    "                    filas.append({\n",
    "                        'Estado': estado_act,\n",
    "                        'Codigo': cod,\n",
    "                        'Actividad': desc,\n",
    "                        'Sector': clasificar(cod), \n",
    "                        'Inversion': val_act, \n",
    "                        'Inversion_Anterior': val_prev\n",
    "                    })\n",
    "            elif not c[0].isdigit() and \"total\" not in c.lower() and \"nota\" not in c.lower():\n",
    "                estado_act = c\n",
    "        \n",
    "        df_clean = pd.DataFrame(filas)\n",
    "        if not df_clean.empty:\n",
    "            df_clean = limpiar_columna_estado(df_clean)\n",
    "\n",
    "        if not df_clean.empty:\n",
    "            df_totales = df_clean.groupby(['Estado', 'Sector'])[['Inversion', 'Inversion_Anterior']].sum().reset_index()\n",
    "            \n",
    "            df_totales['Anio'] = last_period[0]\n",
    "            df_totales['Trimestre'] = last_period[1]\n",
    "            \n",
    "            df_totales.to_csv(os.path.join(INTERMEDIATE_DIR, \"ied_totales.csv\"), index=False)\n",
    "            \n",
    "            tops = []\n",
    "            for est in df_clean['Estado'].unique():\n",
    "                d_est = df_clean[df_clean['Estado'] == est]\n",
    "                for sec in ['Primaria', 'Secundaria', 'Terciaria']:\n",
    "                    d_sec = d_est[d_est['Sector'] == sec]\n",
    "                    top3 = d_sec.sort_values('Inversion', ascending=False).head(3).copy()\n",
    "                    tops.append(top3)\n",
    "            \n",
    "            if tops:\n",
    "                df_tops = pd.concat(tops)\n",
    "                \n",
    "                df_tops['Anio'] = last_period[0]\n",
    "                df_tops['Trimestre'] = last_period[1]\n",
    "                \n",
    "                df_tops.to_csv(os.path.join(INTERMEDIATE_DIR, \"ied_top3_sectores.csv\"), index=False)\n",
    "                return f\"‚úÖ [IED] Completado (Periodo {last_period}).\"\n",
    "        \n",
    "        return \"‚ö†Ô∏è [IED] Sin datos extra√≠dos.\"\n",
    "        \n",
    "    except Exception as e: return f\"‚ùå [IED] Error: {e}\"\n",
    "\n",
    "# ==========================================\n",
    "# M√ìDULO 7: SAIC (Local)\n",
    "# ==========================================\n",
    "def procesar_saic():\n",
    "    print(\"‚è≥ [SAIC] Procesando censo...\")\n",
    "    fpath = os.path.join(RAW_DIR, \"SAIC.xlsx\")\n",
    "    if not os.path.exists(fpath): return f\"‚ö†Ô∏è [SAIC] Falta {fpath}\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(fpath, header=4)\n",
    "        df = df.iloc[:, [0, 1, 3, 4]]\n",
    "        df.columns = ['Anio_Censal', 'Entidad', 'Personal_Ocupado', 'Produccion_Bruta']\n",
    "        \n",
    "        df = df.dropna(how='all')\n",
    "        df = df[~df['Anio_Censal'].astype(str).str.lower().str.startswith('nota')]\n",
    "        df = df.dropna(subset=['Entidad'])\n",
    "        \n",
    "        def clean_entidad(val):\n",
    "            return re.sub(r'^\\d+\\s+', '', str(val).strip())\n",
    "\n",
    "        def clean_numeric(val):\n",
    "            if pd.isna(val): return 0.0\n",
    "            if isinstance(val, str):\n",
    "                val = val.replace(',', '').strip()\n",
    "                if val == '' or val == '-': return 0.0\n",
    "            return float(val)\n",
    "\n",
    "        df['Entidad'] = df['Entidad'].apply(clean_entidad)\n",
    "        df = limpiar_columna_estado(df)\n",
    "        df['Personal_Ocupado'] = df['Personal_Ocupado'].apply(clean_numeric)\n",
    "        df['Produccion_Bruta'] = df['Produccion_Bruta'].apply(clean_numeric)\n",
    "\n",
    "        df['Indicador_Productividad'] = df.apply(\n",
    "            lambda row: (row['Produccion_Bruta'] / row['Personal_Ocupado']) * 1000\n",
    "            if row['Personal_Ocupado'] != 0 else 0.0, \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        cols_finales = ['Anio_Censal', 'Entidad', 'Personal_Ocupado', 'Produccion_Bruta', 'Indicador_Productividad']\n",
    "        df = df[cols_finales]\n",
    "        \n",
    "        df.to_csv(os.path.join(INTERMEDIATE_DIR, \"saic_productividad.csv\"), index=False)\n",
    "        return \"‚úÖ [SAIC] Completado.\"\n",
    "        \n",
    "    except Exception as e: return f\"‚ùå [SAIC] Error: {e}\"\n",
    "\n",
    "# ==========================================\n",
    "# M√ìDULO 8: IMCO (Local)\n",
    "# ==========================================\n",
    "def procesar_imco():\n",
    "    print(\"‚è≥ [IMCO] Procesando competitividad...\")\n",
    "    f_gen = os.path.join(RAW_DIR, \"imco_general.csv\")\n",
    "    f_des = os.path.join(RAW_DIR, \"imco_desagregado.csv\")\n",
    "    if not os.path.exists(f_gen) or not os.path.exists(f_des): return \"‚ö†Ô∏è [IMCO] Faltan archivos.\"\n",
    "    \n",
    "    try:\n",
    "        # General\n",
    "        try: df_g = pd.read_csv(f_gen, encoding='utf-8')\n",
    "        except: df_g = pd.read_csv(f_gen, encoding='latin-1')\n",
    "        cols_map = {c: 'A√±o' if 'A√É¬±o' in c else 'Cambio' if 'posici√É¬≥n' in c else c for c in df_g.columns}\n",
    "        df_g.rename(columns=cols_map, inplace=True)\n",
    "        df_g = df_g[df_g['A√±o'] == df_g['A√±o'].max()]\n",
    "        df_g = limpiar_columna_estado(df_g)\n",
    "        df_g.to_csv(os.path.join(INTERMEDIATE_DIR, \"imco_general_final.csv\"), index=False)\n",
    "        \n",
    "        # Desagregado\n",
    "        try: df_d = pd.read_csv(f_des, encoding='utf-8')\n",
    "        except: df_d = pd.read_csv(f_des, encoding='latin-1')\n",
    "        cols_map_d = {c: 'Sub√≠ndice' if 'Sub√É¬≠ndice' in c else c for c in df_d.columns}\n",
    "        df_d.rename(columns=cols_map_d, inplace=True)\n",
    "        df_d = limpiar_columna_estado(df_d)\n",
    "        \n",
    "        fechas = sorted(df_d['Date'].unique(), reverse=True)[:2]\n",
    "        df_d = df_d[df_d['Date'].isin(fechas)].copy()\n",
    "        df_d['Rank'] = df_d.groupby(['Date', 'Indicador'])['Value'].rank(ascending=False, method='min')\n",
    "        \n",
    "        if len(fechas) >= 2:\n",
    "            df_curr = df_d[df_d['Date'] == fechas[0]].copy()\n",
    "            df_prev = df_d[df_d['Date'] == fechas[1]][['Entidad', 'Indicador', 'Rank']].rename(columns={'Rank': 'Rank_Prev'})\n",
    "            df_fin = df_curr.merge(df_prev, on=['Entidad', 'Indicador'], how='left')\n",
    "            df_fin['Cambio_Posicion'] = df_fin['Rank_Prev'] - df_fin['Rank']\n",
    "            df_fin['Cambio_Posicion'] = df_fin['Cambio_Posicion'].fillna(0)\n",
    "        else:\n",
    "            df_fin = df_d; df_fin['Cambio_Posicion'] = 0\n",
    "            \n",
    "        df_fin.to_csv(os.path.join(INTERMEDIATE_DIR, \"imco_desagregado_final.csv\"), index=False)\n",
    "        return \"‚úÖ [IMCO] Completado.\"\n",
    "    except Exception as e: return f\"‚ùå [IMCO] Error: {e}\"\n",
    "\n",
    "# ==========================================\n",
    "# ORQUESTADOR\n",
    "# ==========================================\n",
    "def main():\n",
    "    inicio = time.time()\n",
    "    print(\"\\nüöÄ INICIANDO ETL ESTATAL UNIFICADO üöÄ\\n\")\n",
    "    \n",
    "    tareas = [\n",
    "        procesar_pib, procesar_exportaciones, procesar_poblacion_api, \n",
    "        procesar_enoe_auto, procesar_educacion, procesar_ied, \n",
    "        procesar_saic, procesar_imco\n",
    "    ]\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futuros = {executor.submit(t): t.__name__ for t in tareas}\n",
    "        for futuro in concurrent.futures.as_completed(futuros):\n",
    "            print(f\"{futuro.result()}\")\n",
    "                \n",
    "    print(f\"\\n‚ú® PROCESO TERMINADO EN {time.time()-inicio:.2f} SEGUNDOS ‚ú®\")\n",
    "    print(f\"üìÇ Archivos en: {INTERMEDIATE_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
