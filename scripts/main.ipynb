{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10152313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ RaÃ­z del Proyecto: c:\\Users\\Edward\\Desktop\\Bancomext\\Estatales\n",
      "ðŸ“‚ Datos Crudos: c:\\Users\\Edward\\Desktop\\Bancomext\\Estatales\\data\\raw\n",
      "ðŸ“‚ Datos Procesados: c:\\Users\\Edward\\Desktop\\Bancomext\\Estatales\\data\\intermediate\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸš€ INICIANDO ETL ESTATAL UNIFICADO ðŸš€\n",
      "\n",
      "â³ [PIB] Iniciando extracciÃ³n exhaustiva...\n",
      "â³ [Exportaciones] Iniciando extracciÃ³n detallada...\n",
      "â³ [PoblaciÃ³n] Iniciando extracciÃ³n de pirÃ¡mide completa...\n",
      "â³ [ENOE] Iniciando descarga y procesamiento...\n",
      "â³ [EducaciÃ³n] Procesando anuario (Generando Top 3 separados)...\n",
      "â³ [IED] Procesando datos complejos (Totales 3 DÃ­gitos y Detalle)...\n",
      "â³ [SAIC] Procesando censo...\n",
      "â³ [IMCO] Procesando competitividad...\n",
      "â³ [Salarios IMSS] Iniciando extracciÃ³n de 32 estados con Selenium...\n",
      "âœ… [IMCO] Completado.\n",
      "â³ [Puestos IMSS] Iniciando extracciÃ³n directa con Selenium...\n",
      "âœ… [SAIC] Completado.\n",
      "   ðŸ“¥ Descargando: https://www.inegi.org.mx/contenidos/programas/enoe/15ymas/tabulados/enoe_indicadores_estrategicos_2025_trim4_xls.zip\n",
      "âœ… [EducaciÃ³n] Completado (Totales + 2 Archivos Top3 - Ciclo 2024-2025).\n",
      "âœ… [ENOE] Completado (2025-trim4).\n",
      "âœ… [IED] Completado (Periodo (2025, 3)).\n",
      "âœ… [Puestos IMSS] Completado. Archivo guardado.\n",
      "âœ… [Exportaciones] Completado (3383 registros).\n",
      "âœ… [PoblaciÃ³n] Completado (1386 registros).\n",
      "âœ… [PIB] Completado (2772 registros).\n",
      "âœ… [Salarios IMSS] Completado. Archivo consolidado guardado.\n",
      "\n",
      "âœ¨ PROCESO TERMINADO EN 1015.90 SEGUNDOS âœ¨\n",
      "ðŸ“‚ Archivos en: c:\\Users\\Edward\\Desktop\\Bancomext\\Estatales\\data\\intermediate\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import io\n",
    "import re\n",
    "import concurrent.futures\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import glob\n",
    "\n",
    "def homologar_estado(nombre):\n",
    "    if not isinstance(nombre, str): return nombre\n",
    "    n = nombre.lower()\n",
    "    \n",
    "    if 'ciudad de mÃ©xico' in n or 'ciudad de mexico' in n or 'cdmx' in n or 'distrito federal' in n: return 'Ciudad de MÃ©xico'\n",
    "    if 'baja california sur' in n: return 'Baja California Sur'\n",
    "    if 'baja california' in n: return 'Baja California'\n",
    "    if 'estado de mÃ©xico' in n or 'estado de mexico' in n or n.strip() == 'mÃ©xico' or n.strip() == 'mexico': return 'MÃ©xico'\n",
    "    \n",
    "    if 'coahuila' in n: return 'Coahuila'\n",
    "    if 'michoacÃ¡n' in n or 'michoacan' in n: return 'MichoacÃ¡n'\n",
    "    if 'veracruz' in n: return 'Veracruz'\n",
    "    if 'nuevo leÃ³n' in n or 'nuevo leon' in n: return 'Nuevo LeÃ³n'\n",
    "    if 'querÃ©taro' in n or 'queretaro' in n: return 'QuerÃ©taro'\n",
    "    if 'san luis' in n: return 'San Luis PotosÃ­'\n",
    "    if 'yucatÃ¡n' in n or 'yucatan' in n: return 'YucatÃ¡n'\n",
    "    \n",
    "    estados = ['Aguascalientes', 'Campeche', 'Colima', 'Chiapas', 'Chihuahua', \n",
    "               'Durango', 'Guanajuato', 'Guerrero', 'Hidalgo', 'Jalisco', \n",
    "               'Morelos', 'Nayarit', 'Oaxaca', 'Puebla', 'Quintana Roo', \n",
    "               'Sinaloa', 'Sonora', 'Tabasco', 'Tamaulipas', 'Tlaxcala', 'Zacatecas']\n",
    "    \n",
    "    for est in estados:\n",
    "        if est.lower() in n: return est\n",
    "        \n",
    "    return nombre\n",
    "\n",
    "def limpiar_columna_estado(df):\n",
    "    nombres_validos = ['estado', 'entidad', 'entidad federativa', 'estados', 'entidades']\n",
    "    for col in df.columns:\n",
    "        if str(col).lower().strip() in nombres_validos:\n",
    "            df[col] = df[col].apply(homologar_estado)\n",
    "    return df\n",
    "\n",
    "# ==========================================\n",
    "# 0. CONFIGURACIÃ“N GLOBAL Y RUTAS\n",
    "# ==========================================\n",
    "TOKEN_INEGI = \"129ac2e3-e8a6-72c7-58c1-acced5a601bd\"\n",
    "\n",
    "# DetecciÃ³n robusta de directorios\n",
    "try:\n",
    "    SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "    if os.path.basename(SCRIPT_DIR) == 'scripts':\n",
    "        PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)\n",
    "    else:\n",
    "        PROJECT_ROOT = SCRIPT_DIR\n",
    "except NameError:\n",
    "    PROJECT_ROOT = os.getcwd()\n",
    "    if os.path.basename(PROJECT_ROOT) == 'scripts':\n",
    "        PROJECT_ROOT = os.path.dirname(PROJECT_ROOT)\n",
    "\n",
    "RAW_DIR = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "INTERMEDIATE_DIR = os.path.join(PROJECT_ROOT, \"data\", \"intermediate\")\n",
    "\n",
    "os.makedirs(INTERMEDIATE_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"ðŸ“ RaÃ­z del Proyecto: {PROJECT_ROOT}\")\n",
    "print(f\"ðŸ“‚ Datos Crudos: {RAW_DIR}\")\n",
    "print(f\"ðŸ“‚ Datos Procesados: {INTERMEDIATE_DIR}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ==========================================\n",
    "# MÃ“DULO 1: PIB (API)\n",
    "# ==========================================\n",
    "def procesar_pib():\n",
    "    print(\"â³ [PIB] Iniciando extracciÃ³n exhaustiva...\")\n",
    "    indicadores = {\n",
    "        \"746097\": \"Total Nacional\",\n",
    "        \"746196\": \"Actividades Primarias\",\n",
    "        \"746229\": \"Agricultura, crÃ­a y explotaciÃ³n de animales, aprovechamiento forestal, pesca y caza\",\n",
    "        \"746262\": \"Agricultura\",\n",
    "        \"746295\": \"CrÃ­a y explotaciÃ³n de animales\",\n",
    "        \"746328\": \"Pesca, caza y captura\",\n",
    "        \"746361\": \"Aprovechamiento forestal\",\n",
    "        \"746394\": \"Actividades Secundarias\",\n",
    "        \"746427\": \"MinerÃ­a\",\n",
    "        \"746460\": \"MinerÃ­a petrolera\",\n",
    "        \"746493\": \"MinerÃ­a no petrolera\",\n",
    "        \"746526\": \"GeneraciÃ³n, transmisiÃ³n y distribuciÃ³n de energÃ­a elÃ©ctrica, agua y gas\",\n",
    "        \"746559\": \"ConstrucciÃ³n\",\n",
    "        \"746592\": \"Industrias manufactureras\",\n",
    "        \"746625\": \"Industria alimentaria\",\n",
    "        \"746658\": \"Bebidas y tabaco\",\n",
    "        \"746691\": \"Insumos, acabados y productos textiles\",\n",
    "        \"746724\": \"Prendas de vestir y productos de cuero y piel\",\n",
    "        \"746757\": \"Industria de la madera\",\n",
    "        \"746790\": \"Industria del papel\",\n",
    "        \"746823\": \"Productos derivados del petrÃ³leo y carbÃ³n, quÃ­mica, plÃ¡stico y hule\",\n",
    "        \"746856\": \"Productos a base de minerales no metÃ¡licos\",\n",
    "        \"746889\": \"MetÃ¡licas bÃ¡sicas y productos metÃ¡licos\",\n",
    "        \"746922\": \"Maquinaria y equipo, computaciÃ³n, electrÃ³nicos y accesorios\",\n",
    "        \"746955\": \"Muebles, colchones y persianas\",\n",
    "        \"746988\": \"Otras industrias manufactureras\",\n",
    "        \"747021\": \"Actividades Terciarias\",\n",
    "        \"747054\": \"Comercio al por mayor\",\n",
    "        \"747087\": \"Comercio al por menor\",\n",
    "        \"747120\": \"Transportes, correos y almacenamiento\",\n",
    "        \"747153\": \"InformaciÃ³n en medios masivos\",\n",
    "        \"747186\": \"Servicios financieros y de seguros\",\n",
    "        \"747219\": \"Servicios inmobiliarios y de alquiler de bienes\",\n",
    "        \"747252\": \"Servicios profesionales, cientÃ­ficos y tÃ©cnicos\",\n",
    "        \"747285\": \"Corporativos\",\n",
    "        \"747318\": \"Servicios de apoyo a los negocios y manejo de residuos\",\n",
    "        \"747351\": \"Servicios educativos\",\n",
    "        \"747384\": \"Servicios de salud y de asistencia social\",\n",
    "        \"747417\": \"Servicios de esparcimiento culturales y deportivos\",\n",
    "        \"747450\": \"Servicios de alojamiento temporal y de preparaciÃ³n de alimentos y bebidas\",\n",
    "        \"747483\": \"Otros servicios excepto actividades gubernamentales\",\n",
    "        \"747516\": \"Actividades legislativas, gubernamentales\"\n",
    "    }\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for ind_clave, ind_nombre in indicadores.items():\n",
    "        for i in range(0, 33): \n",
    "            clave_estado = f\"{i:02d}\"\n",
    "            url = f\"https://www.inegi.org.mx/app/api/indicadores/desarrolladores/jsonxml/INDICATOR/{ind_clave}/es/{clave_estado}/false/BIE-BISE/2.0/{TOKEN_INEGI}?type=json\"\n",
    "            \n",
    "            exito = False\n",
    "            for intento in range(3):\n",
    "                try:\n",
    "                    r = requests.get(url, timeout=10)\n",
    "                    if r.status_code == 200:\n",
    "                        data = r.json()\n",
    "                        if 'Series' in data and data['Series']:\n",
    "                            serie = data['Series'][0].get('OBSERVATIONS', [])\n",
    "                            serie_sorted = sorted(serie, key=lambda x: x.get('TIME_PERIOD', ''))\n",
    "                            if len(serie_sorted) >= 2:\n",
    "                                obs_list = serie_sorted[-2:]\n",
    "                            else:\n",
    "                                obs_list = serie_sorted\n",
    "                                \n",
    "                            for obs in obs_list:\n",
    "                                resultados.append({\n",
    "                                    'Indicador': ind_nombre,\n",
    "                                    'Clave_Indicador': ind_clave,\n",
    "                                    'Estado_ID': obs.get('COBER_GEO', clave_estado),\n",
    "                                    'Periodo': int(obs.get('TIME_PERIOD')),\n",
    "                                    'Valor': float(obs.get('OBS_VALUE', 0))\n",
    "                                })\n",
    "                        exito = True\n",
    "                        break\n",
    "                    else:\n",
    "                        time.sleep(1)\n",
    "                except Exception:\n",
    "                    time.sleep(1)\n",
    "            time.sleep(0.05)\n",
    "            \n",
    "    if resultados:\n",
    "        df = pd.DataFrame(resultados)\n",
    "        outfile = os.path.join(INTERMEDIATE_DIR, \"pib_entidad.csv\")\n",
    "        df.to_csv(outfile, index=False)\n",
    "        return f\"âœ… [PIB] Completado ({len(df)} registros).\"\n",
    "    return \"âš ï¸ [PIB] No se obtuvieron datos.\"\n",
    "\n",
    "# ==========================================\n",
    "# MÃ“DULO 2: EXPORTACIONES (API)\n",
    "# ==========================================\n",
    "def procesar_exportaciones():\n",
    "    print(\"â³ [Exportaciones] Iniciando extracciÃ³n detallada...\")\n",
    "    indicadores = {\n",
    "        \"629659\": \"Total\",\n",
    "        \"696790\": \"Agricultura\",\n",
    "        \"696791\": \"CrÃ­a y explotaciÃ³n de animales\",\n",
    "        \"697788\": \"Pesca, caza y captura\",\n",
    "        \"629660\": \"ExtracciÃ³n de petrÃ³leo y gas\",\n",
    "        \"629661\": \"MinerÃ­a de minerales metÃ¡licos y no metÃ¡licos\",\n",
    "        \"629662\": \"Industria alimentaria\",\n",
    "        \"629663\": \"Industria de las bebidas y del tabaco\",\n",
    "        \"629664\": \"FabricaciÃ³n de insumos textiles y acabado de textiles\",\n",
    "        \"629665\": \"FabricaciÃ³n de productos textiles, excepto prendas de vestir\",\n",
    "        \"629666\": \"FabricaciÃ³n de prendas de vestir\",\n",
    "        \"629667\": \"Curtido y acabado de cuero y piel, y fabricaciÃ³n de productos de cuero\",\n",
    "        \"629668\": \"Industria de la madera\",\n",
    "        \"629669\": \"Industria del papel\",\n",
    "        \"629670\": \"ImpresiÃ³n e industrias conexas\",\n",
    "        \"629671\": \"FabricaciÃ³n de productos derivados del petrÃ³leo y del carbÃ³n\",\n",
    "        \"629672\": \"Industria quÃ­mica\",\n",
    "        \"629673\": \"Industria del plÃ¡stico y del hule\",\n",
    "        \"629674\": \"FabricaciÃ³n de productos a base de minerales no metÃ¡licos\",\n",
    "        \"629675\": \"Industrias metÃ¡licas bÃ¡sicas\",\n",
    "        \"629676\": \"FabricaciÃ³n de productos metÃ¡licos\",\n",
    "        \"629677\": \"FabricaciÃ³n de maquinaria y equipo\",\n",
    "        \"629678\": \"FabricaciÃ³n de equipo de computaciÃ³n, comunicaciÃ³n, mediciÃ³n y otros equipos, componentes y accesorios electrÃ³nicos\",\n",
    "        \"629679\": \"FabricaciÃ³n de accesorios, aparatos elÃ©ctricos y equipo de generaciÃ³n de energÃ­a elÃ©ctrica\",\n",
    "        \"629680\": \"FabricaciÃ³n de equipo de transporte\",\n",
    "        \"629681\": \"FabricaciÃ³n de muebles, colchones y persianas\",\n",
    "        \"629682\": \"Otras industrias manufactureras\",\n",
    "        \"629683\": \"No especificado\"\n",
    "    }\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for ind_clave, ind_nombre in indicadores.items():\n",
    "        for i in range(1, 33):\n",
    "            clave_estado = f\"{i:02d}\"\n",
    "            url = f\"https://www.inegi.org.mx/app/api/indicadores/desarrolladores/jsonxml/INDICATOR/{ind_clave}/es/{clave_estado}/false/BIE-BISE/2.0/{TOKEN_INEGI}?type=json\"\n",
    "            \n",
    "            exito = False\n",
    "            for intento in range(3):\n",
    "                try:\n",
    "                    r = requests.get(url, timeout=10)\n",
    "                    if r.status_code == 200:\n",
    "                        data = r.json()\n",
    "                        if 'Series' in data and data['Series']:\n",
    "                            serie = data['Series'][0].get('OBSERVATIONS', [])\n",
    "                            serie_sorted = sorted(serie, key=lambda x: x.get('TIME_PERIOD', ''))\n",
    "                            if serie_sorted:\n",
    "                                max_year_str = serie_sorted[-1]['TIME_PERIOD'][:4]\n",
    "                                try:\n",
    "                                    max_year = int(max_year_str)\n",
    "                                    min_year_target = max_year - 1\n",
    "                                    for obs in serie_sorted:\n",
    "                                        anio_obs = int(obs['TIME_PERIOD'][:4])\n",
    "                                        if anio_obs >= min_year_target:\n",
    "                                            resultados.append({\n",
    "                                                'Sector': ind_nombre,\n",
    "                                                'Clave_Indicador': ind_clave,\n",
    "                                                'Estado_ID': clave_estado,\n",
    "                                                'Periodo': obs.get('TIME_PERIOD'),\n",
    "                                                'Valor': float(obs.get('OBS_VALUE', 0))\n",
    "                                            })\n",
    "                                except: pass\n",
    "                        exito = True\n",
    "                        break\n",
    "                    else:\n",
    "                        time.sleep(1)\n",
    "                except Exception:\n",
    "                    time.sleep(1)\n",
    "            time.sleep(0.05)\n",
    "            \n",
    "    if resultados:\n",
    "        df = pd.DataFrame(resultados)\n",
    "        outfile = os.path.join(INTERMEDIATE_DIR, \"exportaciones_entidad.csv\")\n",
    "        df.to_csv(outfile, index=False)\n",
    "        return f\"âœ… [Exportaciones] Completado ({len(df)} registros).\"\n",
    "    return \"âš ï¸ [Exportaciones] No se obtuvieron datos.\"\n",
    "\n",
    "# ==========================================\n",
    "# MÃ“DULO 3: POBLACIÃ“N (API)\n",
    "# ==========================================\n",
    "def procesar_poblacion_api():\n",
    "    print(\"â³ [PoblaciÃ³n] Iniciando extracciÃ³n de pirÃ¡mide completa...\")\n",
    "    indicadores = {\n",
    "        # Hombres\n",
    "        \"1002000059\": \"0 a 4 aÃ±os (Hombres)\",\n",
    "        \"1002000089\": \"5 a 9 aÃ±os (Hombres)\",\n",
    "        \"1002000062\": \"10 a 14 aÃ±os (Hombres)\",\n",
    "        \"1002000068\": \"15 a 19 aÃ±os (Hombres)\",\n",
    "        \"1002000071\": \"20 a 24 aÃ±os (Hombres)\",\n",
    "        \"1002000074\": \"25 a 29 aÃ±os (Hombres)\",\n",
    "        \"1002000077\": \"30 a 34 aÃ±os (Hombres)\",\n",
    "        \"1002000080\": \"35 a 39 aÃ±os (Hombres)\",\n",
    "        \"1002000083\": \"40 a 44 aÃ±os (Hombres)\",\n",
    "        \"1002000086\": \"45 a 49 aÃ±os (Hombres)\",\n",
    "        \"1002000092\": \"50 a 54 aÃ±os (Hombres)\",\n",
    "        \"1002000095\": \"55 a 59 aÃ±os (Hombres)\",\n",
    "        \"1002000098\": \"60 a 64 aÃ±os (Hombres)\",\n",
    "        \"1002000101\": \"65 a 69 aÃ±os (Hombres)\",\n",
    "        \"1002000104\": \"70 a 74 aÃ±os (Hombres)\",\n",
    "        \"1002000107\": \"75 a 79 aÃ±os (Hombres)\",\n",
    "        \"1002000110\": \"80 a 84 aÃ±os (Hombres)\",\n",
    "        \"1002000113\": \"85 a 89 aÃ±os (Hombres)\",\n",
    "        \"1002000116\": \"90 a 94 aÃ±os (Hombres)\",\n",
    "        \"1002000119\": \"95 a 99 aÃ±os (Hombres)\",\n",
    "        \"1002000065\": \"100 aÃ±os y mÃ¡s (Hombres)\",\n",
    "\n",
    "        # Mujeres\n",
    "        \"1002000060\": \"0 a 4 aÃ±os (Mujeres)\",\n",
    "        \"1002000090\": \"5 a 9 aÃ±os (Mujeres)\",\n",
    "        \"1002000063\": \"10 a 14 aÃ±os (Mujeres)\",\n",
    "        \"1002000069\": \"15 a 19 aÃ±os (Mujeres)\",\n",
    "        \"1002000072\": \"20 a 24 aÃ±os (Mujeres)\",\n",
    "        \"1002000075\": \"25 a 29 aÃ±os (Mujeres)\",\n",
    "        \"1002000078\": \"30 a 34 aÃ±os (Mujeres)\",\n",
    "        \"1002000081\": \"35 a 39 aÃ±os (Mujeres)\",\n",
    "        \"1002000084\": \"40 a 44 aÃ±os (Mujeres)\",\n",
    "        \"1002000087\": \"45 a 49 aÃ±os (Mujeres)\",\n",
    "        \"1002000093\": \"50 a 54 aÃ±os (Mujeres)\",\n",
    "        \"1002000096\": \"55 a 59 aÃ±os (Mujeres)\",\n",
    "        \"1002000099\": \"60 a 64 aÃ±os (Mujeres)\",\n",
    "        \"1002000102\": \"65 a 69 aÃ±os (Mujeres)\",\n",
    "        \"1002000105\": \"70 a 74 aÃ±os (Mujeres)\",\n",
    "        \"1002000108\": \"75 a 79 aÃ±os (Mujeres)\",\n",
    "        \"1002000111\": \"80 a 84 aÃ±os (Mujeres)\",\n",
    "        \"1002000114\": \"85 a 89 aÃ±os (Mujeres)\",\n",
    "        \"1002000117\": \"90 a 94 aÃ±os (Mujeres)\",\n",
    "        \"1002000120\": \"95 a 99 aÃ±os (Mujeres)\",\n",
    "        \"1002000066\": \"100 aÃ±os y mÃ¡s (Mujeres)\"\n",
    "}\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for ind_clave, desc in indicadores.items():\n",
    "        for i in range(0, 33):\n",
    "            url = f\"https://www.inegi.org.mx/app/api/indicadores/desarrolladores/jsonxml/INDICATOR/{ind_clave}/es/{i:02d}/true/BISE/2.0/{TOKEN_INEGI}?type=json\"\n",
    "            \n",
    "            exito = False\n",
    "            for intento in range(3):\n",
    "                try:\n",
    "                    r = requests.get(url, timeout=5)\n",
    "                    if r.status_code == 200:\n",
    "                        data = r.json()\n",
    "                        if 'Series' in data and data['Series']:\n",
    "                            obs = data['Series'][0]['OBSERVATIONS'][0]\n",
    "                            resultados.append({\n",
    "                                'Indicador': desc,\n",
    "                                'Clave_Indicador': ind_clave,\n",
    "                                'Estado_ID': f\"{i:02d}\",\n",
    "                                'Periodo': obs.get('TIME_PERIOD'),\n",
    "                                'Valor': float(obs.get('OBS_VALUE', 0))\n",
    "                            })\n",
    "                        exito = True\n",
    "                        break\n",
    "                    else:\n",
    "                        time.sleep(0.5)\n",
    "                except Exception:\n",
    "                    time.sleep(0.5)\n",
    "            time.sleep(0.02)\n",
    "            \n",
    "    if resultados:\n",
    "        df = pd.DataFrame(resultados)\n",
    "        outfile = os.path.join(INTERMEDIATE_DIR, \"poblacion_edad.csv\")\n",
    "        df.to_csv(outfile, index=False)\n",
    "        return f\"âœ… [PoblaciÃ³n] Completado ({len(df)} registros).\"\n",
    "    return \"âš ï¸ [PoblaciÃ³n] No se obtuvieron datos.\"\n",
    "\n",
    "# ==========================================\n",
    "# MÃ“DULO 4: ENOE (Descarga + PEA Corregida)\n",
    "# ==========================================\n",
    "def procesar_enoe_auto():\n",
    "    print(\"â³ [ENOE] Iniciando descarga y procesamiento...\")\n",
    "    \n",
    "    base_url = \"https://www.inegi.org.mx/contenidos/programas/enoe/15ymas/tabulados/\"\n",
    "    anio_actual = datetime.now().year\n",
    "    url_final, anio_found, trim_found = None, None, None\n",
    "    \n",
    "    encontrado = False\n",
    "    for a in [anio_actual, anio_actual-1]:\n",
    "        if encontrado: break\n",
    "        for t in [\"trim4\", \"trim3\", \"trim2\", \"trim1\"]:\n",
    "            test_url = f\"{base_url}enoe_indicadores_estrategicos_{a}_{t}_xls.zip\"\n",
    "            try:\n",
    "                r = requests.head(test_url, timeout=5)\n",
    "                content_type = r.headers.get('Content-Type', '').lower()\n",
    "                if r.status_code == 200 and ('zip' in content_type or 'octet-stream' in content_type):\n",
    "                    url_final = test_url; anio_found = a; trim_found = t; encontrado = True\n",
    "                    break\n",
    "            except: pass\n",
    "            \n",
    "    if not url_final: return \"âŒ [ENOE] URL no encontrada.\"\n",
    "\n",
    "    try:\n",
    "        print(f\"   ðŸ“¥ Descargando: {url_final}\")\n",
    "        r = requests.get(url_final)\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        \n",
    "        archivos = [f for f in z.namelist() if (\"Entidades/\" in f or \"Nacional/\" in f) and (f.endswith('.xlsx') or f.endswith('.xls'))]\n",
    "        \n",
    "        datos = []\n",
    "        \n",
    "        config_enoe = {\n",
    "            \"Poblacion Total\": [\"\", \"PoblaciÃ³n total\"],\n",
    "            \"PEA\": [\"\", \"PoblaciÃ³n econÃ³micamente activa (PEA)\"],\n",
    "            \"Desocupada\": [\"PoblaciÃ³n econÃ³micamente activa\", \"Desocupada\"],\n",
    "            \"Edad Promedio PEA\": [\"Edad de la poblaciÃ³n econÃ³micamente activa\", \"Promedio\"],\n",
    "            \"Sector Primario\": [\"3.2 Sector de actividad\", \"Primario\"],\n",
    "            \"Sector Secundario\": [\"3.2 Sector de actividad\", \"Secundario\"],\n",
    "            \"Sector Terciario\": [\"3.2 Sector de actividad\", \"Terciario\"],\n",
    "            \"No especificado\": [\"3.2 Sector de actividad\", \"No especificado\"],\n",
    "            \"Educacion Sup\": [\"Nivel de instrucciÃ³n\", \"Medio superior y superior\"],\n",
    "            \"Informalidad TIL1\": [\"\", \"Tasa de informalidad laboral 1 (TIL1)\"]\n",
    "        }\n",
    "\n",
    "        for arch in archivos:\n",
    "            if \"Nacional\" in arch:\n",
    "                estado = \"Nacional\"\n",
    "            else:\n",
    "                estado = arch.split(\"Entidad_\")[-1].replace(\".xlsx\", \"\").replace(\".xls\", \"\").replace(\"_\", \" \").title()\n",
    "                \n",
    "            with z.open(arch) as f:\n",
    "                df = pd.read_excel(f, header=None)\n",
    "            \n",
    "            registro = {'Estado': estado, 'Anio': anio_found, 'Trimestre': trim_found}\n",
    "            \n",
    "            col_val = 4 \n",
    "            for idx, row in df.iterrows():\n",
    "                txt = \" \".join([str(x).lower() for x in row[:5]])\n",
    "                if \"poblaciÃ³n total\" in txt:\n",
    "                    for c in range(4, min(15, len(row))):\n",
    "                        try:\n",
    "                            if float(str(row[c]).replace(\",\",\"\").replace(\" \", \"\")) > 1000: \n",
    "                                col_val = c; break\n",
    "                        except: continue\n",
    "                    break\n",
    "            \n",
    "            context = {i:\"\" for i in range(5)}\n",
    "            sticky = {1:\"\"}\n",
    "            \n",
    "            for idx, row in df.iterrows():\n",
    "                cols = [str(row[i]).strip() if i < len(row) and pd.notna(row[i]) else \"\" for i in range(5)]\n",
    "                indent = -1\n",
    "                txt_row = \"\"\n",
    "                \n",
    "                for i, txt in enumerate(cols):\n",
    "                    if txt:\n",
    "                        indent = i; txt_row = txt; context[i] = txt\n",
    "                        for j in range(i+1, 5): \n",
    "                            context[j] = \"\"; \n",
    "                            if j in sticky: sticky[j]=\"\"\n",
    "                        break\n",
    "                \n",
    "                if not txt_row: continue\n",
    "                \n",
    "                if indent == 1 and re.match(r'^(\\d+\\.?\\d*)\\s', txt_row): sticky[1] = txt_row\n",
    "                \n",
    "                path = [context[0]]\n",
    "                if indent == 1 and not re.match(r'^(\\d+\\.?\\d*)\\s', txt_row) and sticky[1]:\n",
    "                    path.append(sticky[1]); path.append(txt_row)\n",
    "                else: path.append(context[1])\n",
    "                path += [context[k] for k in range(2,5)]\n",
    "                \n",
    "                path_str = \" | \".join([p.lower() for p in path if p])\n",
    "                \n",
    "                for kpi, (padre, target) in config_enoe.items():\n",
    "                    if target.lower() in txt_row.lower() and padre.lower() in path_str:\n",
    "                        try: \n",
    "                            val_str = str(row[col_val]).replace(\",\",\"\").replace(\" \", \"\")\n",
    "                            registro[kpi] = float(val_str)\n",
    "                        except: pass\n",
    "            \n",
    "            datos.append(registro)\n",
    "\n",
    "        df_out = pd.DataFrame(datos)\n",
    "        df_out = limpiar_columna_estado(df_out)\n",
    "        outfile = os.path.join(INTERMEDIATE_DIR, \"enoe_indicadores.csv\")\n",
    "        df_out.to_csv(outfile, index=False)\n",
    "        return f\"âœ… [ENOE] Completado ({anio_found}-{trim_found}).\"\n",
    "        \n",
    "    except Exception as e: return f\"âŒ [ENOE] Error: {e}\"\n",
    "\n",
    "# ==========================================\n",
    "# MÃ“DULO 5: EDUCACIÃ“N (Local)\n",
    "# ==========================================\n",
    "def procesar_educacion():\n",
    "    print(\"â³ [EducaciÃ³n] Procesando anuario (Generando Top 3 separados)...\")\n",
    "    \n",
    "    archivos = [f for f in os.listdir(RAW_DIR) if f.startswith(\"base_anuario_\") and f.endswith(\".xlsx\")]\n",
    "    if not archivos:\n",
    "        return \"âš ï¸ [EducaciÃ³n] Falta archivo base_anuario_####-####.xlsx\"\n",
    "    \n",
    "    archivo_anuario = archivos[0]\n",
    "    fpath = os.path.join(RAW_DIR, archivo_anuario)\n",
    "    \n",
    "    match = re.search(r'base_anuario_(\\d{4}-\\d{4})\\.xlsx', archivo_anuario)\n",
    "    ciclo_val = match.group(1) if match else \"Â¿?\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(fpath, sheet_name=\"Base de datos\")\n",
    "        \n",
    "        # Limpieza de columnas numÃ©ricas\n",
    "        cols_num = ['MatrÃ­cula Total', 'Egresados Total']\n",
    "        for c in cols_num: \n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)\n",
    "        \n",
    "        mapa_niveles = {\n",
    "            'TÃ‰CNICO SUPERIOR': 'TÃ©cnico Superior', 'LICENCIATURA EN EDUCACIÃ“N NORMAL': 'Licenciatura',\n",
    "            'LICENCIATURA UNIVERSITARIA Y TECNOLÃ“GICA': 'Licenciatura', 'ESPECIALIDAD': 'Licenciatura',\n",
    "            'MAESTRÃA': 'MaestrÃ­a', 'DOCTORADO': 'Doctorado'\n",
    "        }\n",
    "        df['Nivel_Agrupado'] = df['NIVEL'].str.upper().str.strip().map(mapa_niveles)\n",
    "        df = limpiar_columna_estado(df)\n",
    "        \n",
    "        # --- 1. TOTALES (INTACTO) ---\n",
    "        df_totales = df.groupby(['ENTIDAD', 'Nivel_Agrupado'])[cols_num].sum().reset_index()\n",
    "        df_totales['Ciclo'] = ciclo_val\n",
    "        df_totales.to_csv(os.path.join(INTERMEDIATE_DIR, \"educacion_totales.csv\"), index=False)\n",
    "        \n",
    "        df_campos = df.groupby(['ENTIDAD', 'Nivel_Agrupado', 'CAMPO AMPLIO'])[cols_num].sum().reset_index()\n",
    "        \n",
    "        df_nivels = df_campos.groupby(['ENTIDAD', 'Nivel_Agrupado'])[cols_num].sum().reset_index().rename(columns={\n",
    "            'MatrÃ­cula Total': 'Total_Mat', \n",
    "            'Egresados Total': 'Total_Egr'\n",
    "        })\n",
    "        df_campos = df_campos.merge(df_nivels, on=['ENTIDAD', 'Nivel_Agrupado'])\n",
    "        \n",
    "        df_campos['Participacion_Matricula'] = df_campos.apply(lambda x: (x['MatrÃ­cula Total']/x['Total_Mat']*100) if x['Total_Mat']>0 else 0, axis=1)\n",
    "        df_campos['Participacion_Egresados'] = df_campos.apply(lambda x: (x['Egresados Total']/x['Total_Egr']*100) if x['Total_Egr']>0 else 0, axis=1)\n",
    "        \n",
    "        top_mat = df_campos.sort_values(['ENTIDAD', 'Nivel_Agrupado', 'MatrÃ­cula Total'], ascending=[True, True, False])\n",
    "        top_mat = top_mat.groupby(['ENTIDAD', 'Nivel_Agrupado']).head(3).copy()\n",
    "        top_mat['Ciclo'] = ciclo_val\n",
    "        \n",
    "        cols_mat = ['ENTIDAD', 'Nivel_Agrupado', 'CAMPO AMPLIO', 'MatrÃ­cula Total', 'Participacion_Matricula', 'Ciclo']\n",
    "        top_mat[cols_mat].to_csv(os.path.join(INTERMEDIATE_DIR, \"educacion_top3_matricula.csv\"), index=False)\n",
    "        \n",
    "        top_egr = df_campos.sort_values(['ENTIDAD', 'Nivel_Agrupado', 'Egresados Total'], ascending=[True, True, False])\n",
    "        top_egr = top_egr.groupby(['ENTIDAD', 'Nivel_Agrupado']).head(3).copy()\n",
    "        top_egr['Ciclo'] = ciclo_val\n",
    "        \n",
    "        cols_egr = ['ENTIDAD', 'Nivel_Agrupado', 'CAMPO AMPLIO', 'Egresados Total', 'Participacion_Egresados', 'Ciclo']\n",
    "        top_egr[cols_egr].to_csv(os.path.join(INTERMEDIATE_DIR, \"educacion_top3_egresados.csv\"), index=False)\n",
    "        \n",
    "        return f\"âœ… [EducaciÃ³n] Completado (Totales + 2 Archivos Top3 - Ciclo {ciclo_val}).\"\n",
    "        \n",
    "    except Exception as e: return f\"âŒ [EducaciÃ³n] Error: {e}\"\n",
    "# ==========================================\n",
    "# MÃ“DULO 6: IED (Local) - GRUPOS POR SECTOR Y SIN %\n",
    "# ==========================================\n",
    "def procesar_ied():\n",
    "    print(\"â³ [IED] Procesando datos complejos (Totales 3 DÃ­gitos y Detalle)...\")\n",
    "    fpath = os.path.join(RAW_DIR, \"2025_3T_Flujosporentidadfederativa_orig__11_A1.xlsx\")\n",
    "    \n",
    "    if not os.path.exists(fpath): \n",
    "        return f\"âš ï¸ [IED] Falta {fpath}\"\n",
    "    \n",
    "    try:\n",
    "        # 1. MAPEO DE COLUMNAS\n",
    "        df_head = pd.read_excel(fpath, sheet_name='Actividad econÃ³mica_SCIAN 2023', header=None, nrows=10)\n",
    "        \n",
    "        header_idx = None\n",
    "        for idx, row in df_head.iterrows():\n",
    "            if \"Entidad Federativa\" in str(row[0]):\n",
    "                header_idx = idx\n",
    "                break\n",
    "        \n",
    "        if header_idx is None: return \"âŒ [IED] Sin encabezados.\"\n",
    "        \n",
    "        years_row = df_head.iloc[header_idx].tolist()\n",
    "        quarters_row = df_head.iloc[header_idx + 1].tolist()\n",
    "        \n",
    "        col_map = {}\n",
    "        current_year = None\n",
    "        for i in range(1, len(years_row)):\n",
    "            if pd.notna(years_row[i]):\n",
    "                try:\n",
    "                    y = int(float(years_row[i]))\n",
    "                    if y > 2000: current_year = y\n",
    "                except: pass\n",
    "            if current_year and pd.notna(quarters_row[i]):\n",
    "                try:\n",
    "                    q = int(float(quarters_row[i]))\n",
    "                    if 1 <= q <= 4: col_map[i] = (current_year, q)\n",
    "                except: pass\n",
    "        \n",
    "        if not col_map: return \"âŒ [IED] Error mapeo columnas.\"\n",
    "        \n",
    "        last_period = max(col_map.values()) # (AÃ±o, Trim)\n",
    "        prev_period = (last_period[0]-1, last_period[1])\n",
    "        \n",
    "        idx_act = [k for k, v in col_map.items() if v == last_period][0]\n",
    "        idx_prev = [k for k, v in col_map.items() if v == prev_period]\n",
    "        idx_prev = idx_prev[0] if idx_prev else None\n",
    "        \n",
    "        # 2. EXTRACCIÃ“N (Solo 3 dÃ­gitos)\n",
    "        df_data = pd.read_excel(fpath, sheet_name='Actividad econÃ³mica_SCIAN 2023', header=header_idx+2)\n",
    "        \n",
    "        def clean(x):\n",
    "            if pd.isna(x): return 0.0\n",
    "            s = str(x).strip().replace(',','')\n",
    "            try: return float(s)\n",
    "            except: return 0.0\n",
    "            \n",
    "        def clasificar(cod):\n",
    "            if cod.startswith('1'): return 'Primaria'\n",
    "            if cod.startswith(('2','3')): return 'Secundaria'\n",
    "            return 'Terciaria'\n",
    "            \n",
    "        filas = []\n",
    "        estado_act = None\n",
    "        \n",
    "        for i, row in df_data.iterrows():\n",
    "            c = str(row.iloc[0]).strip()\n",
    "            if not c or c == 'nan': continue\n",
    "            \n",
    "            match = re.match(r'^(\\d{2,6}|31-33)\\s+(.*)', c)\n",
    "            if match:\n",
    "                cod, desc = match.groups()\n",
    "                # Filtro Estricto: Solo 3 dÃ­gitos\n",
    "                if len(cod) == 3 and cod != '31-33':\n",
    "                    val_act = clean(row.iloc[idx_act])\n",
    "                    val_prev = clean(row.iloc[idx_prev]) if idx_prev else 0.0\n",
    "                    \n",
    "                    filas.append({\n",
    "                        'Estado': estado_act,\n",
    "                        'Codigo': cod,\n",
    "                        'Actividad': desc,\n",
    "                        'Sector': clasificar(cod), \n",
    "                        'Inversion': val_act, \n",
    "                        'Inversion_Anterior': val_prev\n",
    "                    })\n",
    "            elif not c[0].isdigit() and \"total\" not in c.lower() and \"nota\" not in c.lower():\n",
    "                estado_act = c\n",
    "        \n",
    "        df_clean = pd.DataFrame(filas)\n",
    "        if not df_clean.empty:\n",
    "            df_clean = limpiar_columna_estado(df_clean)\n",
    "\n",
    "        if not df_clean.empty:\n",
    "            df_totales = df_clean.groupby(['Estado', 'Sector'])[['Inversion', 'Inversion_Anterior']].sum().reset_index()\n",
    "            \n",
    "            df_totales['Anio'] = last_period[0]\n",
    "            df_totales['Trimestre'] = last_period[1]\n",
    "            \n",
    "            df_totales.to_csv(os.path.join(INTERMEDIATE_DIR, \"ied_totales.csv\"), index=False)\n",
    "            \n",
    "            tops = []\n",
    "            for est in df_clean['Estado'].unique():\n",
    "                d_est = df_clean[df_clean['Estado'] == est]\n",
    "                for sec in ['Primaria', 'Secundaria', 'Terciaria']:\n",
    "                    d_sec = d_est[d_est['Sector'] == sec]\n",
    "                    top3 = d_sec.sort_values('Inversion', ascending=False).head(3).copy()\n",
    "                    tops.append(top3)\n",
    "            \n",
    "            if tops:\n",
    "                df_tops = pd.concat(tops)\n",
    "                \n",
    "                df_tops['Anio'] = last_period[0]\n",
    "                df_tops['Trimestre'] = last_period[1]\n",
    "                \n",
    "                df_tops.to_csv(os.path.join(INTERMEDIATE_DIR, \"ied_top3_sectores.csv\"), index=False)\n",
    "                return f\"âœ… [IED] Completado (Periodo {last_period}).\"\n",
    "        \n",
    "        return \"âš ï¸ [IED] Sin datos extraÃ­dos.\"\n",
    "        \n",
    "    except Exception as e: return f\"âŒ [IED] Error: {e}\"\n",
    "\n",
    "# ==========================================\n",
    "# MÃ“DULO 7: SAIC (Local)\n",
    "# ==========================================\n",
    "def procesar_saic():\n",
    "    print(\"â³ [SAIC] Procesando censo...\")\n",
    "    fpath = os.path.join(RAW_DIR, \"SAIC.xlsx\")\n",
    "    if not os.path.exists(fpath): return f\"âš ï¸ [SAIC] Falta {fpath}\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(fpath, header=4)\n",
    "        df = df.iloc[:, [0, 1, 3, 4]]\n",
    "        df.columns = ['Anio_Censal', 'Entidad', 'Personal_Ocupado', 'Produccion_Bruta']\n",
    "        \n",
    "        df = df.dropna(how='all')\n",
    "        df = df[~df['Anio_Censal'].astype(str).str.lower().str.startswith('nota')]\n",
    "        df = df.dropna(subset=['Entidad'])\n",
    "        \n",
    "        def clean_entidad(val):\n",
    "            return re.sub(r'^\\d+\\s+', '', str(val).strip())\n",
    "\n",
    "        def clean_numeric(val):\n",
    "            if pd.isna(val): return 0.0\n",
    "            if isinstance(val, str):\n",
    "                val = val.replace(',', '').strip()\n",
    "                if val == '' or val == '-': return 0.0\n",
    "            return float(val)\n",
    "\n",
    "        df['Entidad'] = df['Entidad'].apply(clean_entidad)\n",
    "        df = limpiar_columna_estado(df)\n",
    "        df['Personal_Ocupado'] = df['Personal_Ocupado'].apply(clean_numeric)\n",
    "        df['Produccion_Bruta'] = df['Produccion_Bruta'].apply(clean_numeric)\n",
    "\n",
    "        df['Indicador_Productividad'] = df.apply(\n",
    "            lambda row: (row['Produccion_Bruta'] / row['Personal_Ocupado']) * 1000\n",
    "            if row['Personal_Ocupado'] != 0 else 0.0, \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        cols_finales = ['Anio_Censal', 'Entidad', 'Personal_Ocupado', 'Produccion_Bruta', 'Indicador_Productividad']\n",
    "        df = df[cols_finales]\n",
    "        \n",
    "        df.to_csv(os.path.join(INTERMEDIATE_DIR, \"saic_productividad.csv\"), index=False)\n",
    "        return \"âœ… [SAIC] Completado.\"\n",
    "        \n",
    "    except Exception as e: return f\"âŒ [SAIC] Error: {e}\"\n",
    "\n",
    "# ==========================================\n",
    "# MÃ“DULO 8: IMCO (Local)\n",
    "# ==========================================\n",
    "def procesar_imco():\n",
    "    print(\"â³ [IMCO] Procesando competitividad...\")\n",
    "    f_gen = os.path.join(RAW_DIR, \"imco_general.csv\")\n",
    "    f_des = os.path.join(RAW_DIR, \"imco_desagregado.csv\")\n",
    "    if not os.path.exists(f_gen) or not os.path.exists(f_des): return \"âš ï¸ [IMCO] Faltan archivos.\"\n",
    "    \n",
    "    try:\n",
    "        # General\n",
    "        try: df_g = pd.read_csv(f_gen, encoding='utf-8')\n",
    "        except: df_g = pd.read_csv(f_gen, encoding='latin-1')\n",
    "        cols_map = {c: 'AÃ±o' if 'AÃƒÂ±o' in c else 'Cambio' if 'posiciÃƒÂ³n' in c else c for c in df_g.columns}\n",
    "        df_g.rename(columns=cols_map, inplace=True)\n",
    "        df_g = df_g[df_g['AÃ±o'] == df_g['AÃ±o'].max()]\n",
    "        df_g = limpiar_columna_estado(df_g)\n",
    "        df_g.to_csv(os.path.join(INTERMEDIATE_DIR, \"imco_general_final.csv\"), index=False)\n",
    "        \n",
    "        # Desagregado\n",
    "        try: df_d = pd.read_csv(f_des, encoding='utf-8')\n",
    "        except: df_d = pd.read_csv(f_des, encoding='latin-1')\n",
    "        cols_map_d = {c: 'SubÃ­ndice' if 'SubÃƒÂ­ndice' in c else c for c in df_d.columns}\n",
    "        df_d.rename(columns=cols_map_d, inplace=True)\n",
    "        df_d = limpiar_columna_estado(df_d)\n",
    "        \n",
    "        fechas = sorted(df_d['Date'].unique(), reverse=True)[:2]\n",
    "        df_d = df_d[df_d['Date'].isin(fechas)].copy()\n",
    "        df_d['Rank'] = df_d.groupby(['Date', 'Indicador'])['Value'].rank(ascending=False, method='min')\n",
    "        \n",
    "        if len(fechas) >= 2:\n",
    "            df_curr = df_d[df_d['Date'] == fechas[0]].copy()\n",
    "            df_prev = df_d[df_d['Date'] == fechas[1]][['Entidad', 'Indicador', 'Rank']].rename(columns={'Rank': 'Rank_Prev'})\n",
    "            df_fin = df_curr.merge(df_prev, on=['Entidad', 'Indicador'], how='left')\n",
    "            df_fin['Cambio_Posicion'] = df_fin['Rank_Prev'] - df_fin['Rank']\n",
    "            df_fin['Cambio_Posicion'] = df_fin['Cambio_Posicion'].fillna(0)\n",
    "        else:\n",
    "            df_fin = df_d; df_fin['Cambio_Posicion'] = 0\n",
    "            \n",
    "        df_fin.to_csv(os.path.join(INTERMEDIATE_DIR, \"imco_desagregado_final.csv\"), index=False)\n",
    "        return \"âœ… [IMCO] Completado.\"\n",
    "    except Exception as e: return f\"âŒ [IMCO] Error: {e}\"\n",
    "\n",
    "# ==========================================\n",
    "# MÃ“DULO 9: SALARIOS IMSS (Selenium)\n",
    "# ==========================================\n",
    "def procesar_salarios_imss():\n",
    "    print(\"â³ [Salarios IMSS] Iniciando extracciÃ³n de 32 estados con Selenium...\")\n",
    "    tiempo_inicio_script = time.time() - 2\n",
    "    \n",
    "    # Inicializamos el driver como None para poder cerrarlo de forma segura en caso de error\n",
    "    driver = None \n",
    "    try:\n",
    "        opciones = webdriver.ChromeOptions()\n",
    "        prefs = {\"download.default_directory\" : RAW_DIR}\n",
    "        opciones.add_experimental_option(\"prefs\", prefs)\n",
    "        opciones.add_argument(\"--lang=es-MX\") \n",
    "        \n",
    "        driver = webdriver.Chrome(options=opciones)\n",
    "        driver.get(\"https://public.tableau.com/app/profile/imss.cpe/viz/Histrico_4/Empleo_h?publish=yes\")\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "        df_master = pd.DataFrame()\n",
    "\n",
    "        # A. Manejar el banner de cookies\n",
    "        try:\n",
    "            btn_cookies = wait.until(EC.element_to_be_clickable((By.ID, \"onetrust-accept-btn-handler\")))\n",
    "            btn_cookies.click()\n",
    "            time.sleep(1) \n",
    "        except: pass\n",
    "\n",
    "        # B. Entrar al iFrame y PestaÃ±a\n",
    "        iframe = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"iframe\")))\n",
    "        driver.switch_to.frame(iframe)\n",
    "        \n",
    "        xpath_pestana = \"//div[contains(@class, 'tabStoryPointContent') and contains(normalize-space(), 'Cifras de salario')]\"\n",
    "        tab_salario = wait.until(EC.element_to_be_clickable((By.XPATH, xpath_pestana)))\n",
    "        tab_salario.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        # D y E. Filtro Entidad y (Todo)\n",
    "        xpath_filtro_entidad = \"(//span[@role='combobox'])[1]\"\n",
    "        filtro_entidad = wait.until(EC.element_to_be_clickable((By.XPATH, xpath_filtro_entidad)))\n",
    "        filtro_entidad.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "        xpath_todo_box = \"//div[@role='checkbox' and .//a[@title='(Todo)' or @title='(All)']]//div[@class='fakeCheckBox']\"\n",
    "        try:\n",
    "            box_todo = wait.until(EC.presence_of_element_located((By.XPATH, xpath_todo_box)))\n",
    "            ActionChains(driver).move_to_element(box_todo).click().perform()\n",
    "        except: pass\n",
    "        time.sleep(2) \n",
    "\n",
    "        estados = [\n",
    "            \"Aguascalientes\", \"Baja California\", \"Baja California Sur\", \"Campeche\", \"Chiapas\", \n",
    "            \"Chihuahua\", \"Ciudad de MÃ©xico\", \"Coahuila de Zaragoza\", \"Colima\", \"Durango\", \n",
    "            \"Guanajuato\", \"Guerrero\", \"Hidalgo\", \"Jalisco\", \"MÃ©xico\", \"MichoacÃ¡n de Ocampo\", \n",
    "            \"Morelos\", \"Nayarit\", \"Nuevo LeÃ³n\", \"Oaxaca\", \"Puebla\", \"QuerÃ©taro\", \n",
    "            \"Quintana Roo\", \"San Luis PotosÃ­\", \"Sinaloa\", \"Sonora\", \"Tabasco\", \n",
    "            \"Tamaulipas\", \"Tlaxcala\", \"Veracruz de Ignacio de la Llave\", \"YucatÃ¡n\", \"Zacatecas\"\n",
    "        ]\n",
    "        xpath_search = \"//textarea[contains(@class, 'QueryBox')]\"\n",
    "\n",
    "        for estado in estados:\n",
    "            try:\n",
    "                search_box = wait.until(EC.presence_of_element_located((By.XPATH, xpath_search)))\n",
    "                search_box.send_keys(Keys.CONTROL, \"a\")\n",
    "                search_box.send_keys(Keys.DELETE)\n",
    "                search_box.send_keys(estado)\n",
    "                time.sleep(1) \n",
    "                \n",
    "                xpath_estado_box = f\"//div[@role='checkbox' and .//a[@title='{estado}']]//div[@class='fakeCheckBox']\"\n",
    "                box_estado = wait.until(EC.presence_of_element_located((By.XPATH, xpath_estado_box)))\n",
    "                ActionChains(driver).move_to_element(box_estado).pause(0.5).click().perform()\n",
    "                ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "                time.sleep(2) \n",
    "                \n",
    "                # Proceso de Descarga\n",
    "                xpath_btn_descarga = \"//button[@data-tb-test-id='viz-viewer-toolbar-button-download']\"\n",
    "                btn_descarga = wait.until(EC.presence_of_element_located((By.XPATH, xpath_btn_descarga)))\n",
    "                driver.execute_script(\"arguments[0].click();\", btn_descarga)\n",
    "                time.sleep(1) \n",
    "\n",
    "                xpath_crosstab = \"//div[@data-tb-test-id='download-flyout-download-crosstab-MenuItem']\"\n",
    "                btn_crosstab = wait.until(EC.presence_of_element_located((By.XPATH, xpath_crosstab)))\n",
    "                driver.execute_script(\"arguments[0].click();\", btn_crosstab)\n",
    "                \n",
    "                xpath_csv_label = \"//label[@data-tb-test-id='crosstab-options-dialog-radio-csv-Label']\"\n",
    "                btn_csv = wait.until(EC.presence_of_element_located((By.XPATH, xpath_csv_label)))\n",
    "                driver.execute_script(\"arguments[0].click();\", btn_csv)\n",
    "                time.sleep(1) \n",
    "\n",
    "                xpath_descarga_final = \"//button[@data-tb-test-id='export-crosstab-export-Button']\"\n",
    "                btn_descarga_final = wait.until(EC.presence_of_element_located((By.XPATH, xpath_descarga_final)))\n",
    "                driver.execute_script(\"arguments[0].click();\", btn_descarga_final)\n",
    "                time.sleep(3) \n",
    "                \n",
    "                # Procesamiento con Pandas\n",
    "                prefijo_descarga = \"Salario\" \n",
    "                patron_busqueda = os.path.join(RAW_DIR, f\"{prefijo_descarga}*.csv\")\n",
    "                archivos_candidatos = glob.glob(patron_busqueda)\n",
    "                archivos_validos = [f for f in archivos_candidatos if os.path.getmtime(f) >= tiempo_inicio_script]\n",
    "                \n",
    "                if archivos_validos:\n",
    "                    archivo_reciente = max(archivos_validos, key=os.path.getmtime)\n",
    "                    df_temp = pd.read_csv(\n",
    "                        archivo_reciente, skiprows=1, header=None, usecols=[0, 1], \n",
    "                        names=['Fecha', estado], encoding='utf-16', sep='\\t'\n",
    "                    )\n",
    "                    df_temp['Fecha'] = df_temp['Fecha'].astype(str).str.replace(' de ', ' ', regex=False).str.strip()\n",
    "                    \n",
    "                    if df_master.empty: df_master = df_temp\n",
    "                    else: df_master = pd.merge(df_master, df_temp, on='Fecha', how='outer')\n",
    "                        \n",
    "                    try: os.remove(archivo_reciente)\n",
    "                    except: pass\n",
    "\n",
    "                # Reset\n",
    "                filtro_entidad = wait.until(EC.presence_of_element_located((By.XPATH, xpath_filtro_entidad)))\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", filtro_entidad)\n",
    "                time.sleep(1) \n",
    "                \n",
    "                ActionChains(driver).move_to_element(filtro_entidad).pause(0.5).click().perform()\n",
    "                time.sleep(1) \n",
    "                \n",
    "                search_box = wait.until(EC.presence_of_element_located((By.XPATH, xpath_search)))\n",
    "                search_box.send_keys(Keys.CONTROL, \"a\")\n",
    "                search_box.send_keys(Keys.DELETE)\n",
    "                search_box.send_keys(estado)\n",
    "                time.sleep(1)\n",
    "                \n",
    "                box_estado_limpiar = wait.until(EC.presence_of_element_located((By.XPATH, xpath_estado_box)))\n",
    "                ActionChains(driver).move_to_element(box_estado_limpiar).pause(0.5).click().perform()\n",
    "                time.sleep(1) \n",
    "                \n",
    "                search_box.send_keys(Keys.CONTROL, \"a\")\n",
    "                search_box.send_keys(Keys.DELETE)\n",
    "                time.sleep(1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ [Salarios IMSS] Error procesando {estado}: {e}\")\n",
    "\n",
    "        # Ordenar CronolÃ³gicamente y Guardar\n",
    "        if not df_master.empty:\n",
    "            meses = {\n",
    "                'enero': '01', 'febrero': '02', 'marzo': '03', 'abril': '04',\n",
    "                'mayo': '05', 'junio': '06', 'julio': '07', 'agosto': '08',\n",
    "                'septiembre': '09', 'octubre': '10', 'noviembre': '11', 'diciembre': '12'\n",
    "            }\n",
    "            df_master['Fecha_Temp'] = df_master['Fecha'].str.lower().str.strip()\n",
    "            for mes_nombre, mes_numero in meses.items():\n",
    "                df_master['Fecha_Temp'] = df_master['Fecha_Temp'].str.replace(mes_nombre, f\"{mes_numero}/\", regex=False)\n",
    "            df_master['Fecha_Temp'] = df_master['Fecha_Temp'].str.replace(' ', '', regex=False)\n",
    "            df_master['Fecha_Temp'] = pd.to_datetime(df_master['Fecha_Temp'], format='%m/%Y', errors='coerce')\n",
    "            df_master = df_master.sort_values(by='Fecha_Temp', ascending=True).reset_index(drop=True)\n",
    "            df_master = df_master.drop(columns=['Fecha_Temp'])\n",
    "            \n",
    "            ruta_salida = os.path.join(INTERMEDIATE_DIR, \"salarios_imss.csv\")\n",
    "            df_master.to_csv(ruta_salida, index=False, encoding='utf-8-sig')\n",
    "            \n",
    "            driver.quit()\n",
    "            return f\"âœ… [Salarios IMSS] Completado. Archivo consolidado guardado.\"\n",
    "        else:\n",
    "            driver.quit()\n",
    "            return \"âš ï¸ [Salarios IMSS] El DataFrame maestro estÃ¡ vacÃ­o.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        if driver: driver.quit()\n",
    "        return f\"âŒ [Salarios IMSS] Error general: {e}\"\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# MÃ“DULO 10: PUESTOS IMSS (Selenium)\n",
    "# ==========================================\n",
    "def procesar_puestos_imss():\n",
    "    print(\"â³ [Puestos IMSS] Iniciando extracciÃ³n directa con Selenium...\")\n",
    "    tiempo_inicio_script = time.time() - 2\n",
    "    driver = None\n",
    "    \n",
    "    try:\n",
    "        opciones = webdriver.ChromeOptions()\n",
    "        prefs = {\"download.default_directory\" : RAW_DIR}\n",
    "        opciones.add_experimental_option(\"prefs\", prefs)\n",
    "        opciones.add_argument(\"--lang=es-MX\") \n",
    "        \n",
    "        driver = webdriver.Chrome(options=opciones)\n",
    "        driver.get(\"https://public.tableau.com/app/profile/imss.cpe/viz/Histrico_4/Empleo_h?publish=yes\")\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "\n",
    "        try:\n",
    "            btn_cookies = wait.until(EC.element_to_be_clickable((By.ID, \"onetrust-accept-btn-handler\")))\n",
    "            btn_cookies.click()\n",
    "            time.sleep(1) \n",
    "        except: pass\n",
    "\n",
    "        iframe = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"iframe\")))\n",
    "        driver.switch_to.frame(iframe)\n",
    "        time.sleep(5) \n",
    "\n",
    "        # Proceso de Descarga\n",
    "        xpath_btn_descarga = \"//button[@data-tb-test-id='viz-viewer-toolbar-button-download']\"\n",
    "        btn_descarga = wait.until(EC.presence_of_element_located((By.XPATH, xpath_btn_descarga)))\n",
    "        driver.execute_script(\"arguments[0].click();\", btn_descarga)\n",
    "        time.sleep(1) \n",
    "\n",
    "        xpath_crosstab = \"//div[@data-tb-test-id='download-flyout-download-crosstab-MenuItem']\"\n",
    "        btn_crosstab = wait.until(EC.presence_of_element_located((By.XPATH, xpath_crosstab)))\n",
    "        driver.execute_script(\"arguments[0].click();\", btn_crosstab)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        xpath_csv_label = \"//label[@data-tb-test-id='crosstab-options-dialog-radio-csv-Label']\"\n",
    "        btn_csv = wait.until(EC.presence_of_element_located((By.XPATH, xpath_csv_label)))\n",
    "        driver.execute_script(\"arguments[0].click();\", btn_csv)\n",
    "        time.sleep(1) \n",
    "\n",
    "        xpath_descarga_final = \"//button[@data-tb-test-id='export-crosstab-export-Button']\"\n",
    "        btn_descarga_final = wait.until(EC.presence_of_element_located((By.XPATH, xpath_descarga_final)))\n",
    "        driver.execute_script(\"arguments[0].click();\", btn_descarga_final)\n",
    "        time.sleep(5) \n",
    "\n",
    "        # BÃºsqueda quirÃºrgica y limpieza\n",
    "        prefijo_descarga = \"Nacional\" \n",
    "        patron_busqueda = os.path.join(RAW_DIR, f\"{prefijo_descarga}*.csv\")\n",
    "        archivos_candidatos = glob.glob(patron_busqueda)\n",
    "        archivos_validos = [f for f in archivos_candidatos if os.path.getmtime(f) >= tiempo_inicio_script]\n",
    "\n",
    "        if archivos_validos:\n",
    "            archivo_reciente = max(archivos_validos, key=os.path.getmtime)\n",
    "            df = pd.read_csv(archivo_reciente, skiprows=1, encoding='utf-16', sep='\\t')\n",
    "            \n",
    "            nuevos_nombres = {df.columns[0]: 'AÃ±o', df.columns[1]: 'Mes'}\n",
    "            df.rename(columns=nuevos_nombres, inplace=True)\n",
    "            \n",
    "            try: os.remove(archivo_reciente)\n",
    "            except: pass\n",
    "                \n",
    "            ruta_salida = os.path.join(INTERMEDIATE_DIR, \"puestos_imss.csv\") \n",
    "            df.to_csv(ruta_salida, index=False, encoding='utf-8-sig')\n",
    "            \n",
    "            driver.quit()\n",
    "            return f\"âœ… [Puestos IMSS] Completado. Archivo guardado.\"\n",
    "        else:\n",
    "            driver.quit()\n",
    "            return \"âš ï¸ [Puestos IMSS] No se detectÃ³ ningÃºn archivo CSV descargado.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        if driver: driver.quit()\n",
    "        return f\"âŒ [Puestos IMSS] Error general: {e}\"\n",
    "\n",
    "# ==========================================\n",
    "# ORQUESTADOR\n",
    "# ==========================================\n",
    "def main():\n",
    "    inicio = time.time()\n",
    "    print(\"\\nðŸš€ INICIANDO ETL ESTATAL UNIFICADO ðŸš€\\n\")\n",
    "    \n",
    "    tareas = [\n",
    "        procesar_pib, procesar_exportaciones, procesar_poblacion_api, \n",
    "        procesar_enoe_auto, procesar_educacion, procesar_ied, \n",
    "        procesar_saic, procesar_imco, procesar_salarios_imss, procesar_puestos_imss\n",
    "    ]\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futuros = {executor.submit(t): t.__name__ for t in tareas}\n",
    "        for futuro in concurrent.futures.as_completed(futuros):\n",
    "            print(f\"{futuro.result()}\")\n",
    "                \n",
    "    print(f\"\\nâœ¨ PROCESO TERMINADO EN {time.time()-inicio:.2f} SEGUNDOS âœ¨\")\n",
    "    print(f\"ðŸ“‚ Archivos en: {INTERMEDIATE_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
